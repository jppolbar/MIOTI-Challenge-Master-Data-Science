{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "P3_cdcgan_fashion_mnist.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2x3qooyBTI"
      },
      "source": [
        "# Deep Conditional Convolutional Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZKbyU2-AiY-"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx-zNbLqB4K8"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzTlj4YdCip_"
      },
      "source": [
        "# Generación de GIFs\n",
        "!pip install -q imageio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpmJuG85blWe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "### Carga y prepara el dataset\n",
        "\n",
        "Vas a utilizar el dataset fashion MNIST para entrenar el generador y el discriminador. El generador, por tanto, aprenderá a generar imágenes del mismo tipo que las presentes en fashion MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEOuzkKMfVw1"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByAVg9xefRBu"
      },
      "source": [
        "tfds.list_builders()\n",
        "builder = tfds.builder(\"fashion_mnist\")\n",
        "builder.download_and_prepare()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rM8ISx8fjyT"
      },
      "source": [
        "print(builder.info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHgP5k5vfqzC"
      },
      "source": [
        "(train_dataset_raw) = builder.as_dataset(split=\"train\", as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpuMPiYKftEf"
      },
      "source": [
        "def format_example(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  # scale from [0,255] to [-1,1]\n",
        "  image = (image - 127.5) / 127.5\n",
        "  image = tf.image.resize(image, (28, 28))\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH1XurMHf0tp"
      },
      "source": [
        "train_dataset = train_dataset_raw.map(format_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lybSn8kxJnXc"
      },
      "source": [
        "i = 0\n",
        "for image, label in train_dataset.take(49):\n",
        "  # define subplot\n",
        "  plt.subplot(7, 7, 1 + i)\n",
        "  # turn off axis\n",
        "  plt.axis('off')\n",
        "  # plot raw pixel data\n",
        "  image = (image + 1.0) / 2.0\n",
        "  plt.imshow(image[:,:,0], cmap='gray')\n",
        "  i = i + 1\n",
        "  print(label)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Creación de modelos\n",
        "\n",
        "Tanto el generador como el discriminador van a ser definidos usando la [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tEyxE-GMC48"
      },
      "source": [
        "### El generador\n",
        "\n",
        "El generador utiliza capas `tf.keras.layers.Conv2DTranspose` (upsampling) para producir una imágen a partir de una semilla (ruido aleatorio). Comienza con una capa `Dense`que toma la semilla como entrada, después la escala (upsample) varias veces hasta alcanzar el tamaño de imágen deseado de 28x28x1. Utilizaremos capas de activación `tf.keras.layers.LeakyReLU`, excepto para la capa de salida, que usará tanh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPoRqTIuQFH8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bpTcDqoLWjY"
      },
      "source": [
        "def make_generator_model(n_classes):\n",
        "    # TODO 1: haz tu propio modelo de generador\n",
        "      # Capa input para label\n",
        "      in_label = layers.Input(shape=(1,))\n",
        "      # Generar el embedding pata categorizar las label\n",
        "      li = layers.Embedding(n_classes, 50)(in_label)\n",
        "      # Generamos capa dense con tantas neuronas como dimensiones puede tener la imagen\n",
        "      # que empezamos a crear desde el vesctor de ruido.\n",
        "      n_nodes = 7 * 7\n",
        "      li = layers.Dense(n_nodes)(li)\n",
        "      # Se hace un reshape con las dimensiones de inicial\n",
        "      li = layers.Reshape((7, 7, 1))(li)\n",
        "\n",
        "      # Capa input para el vector de ruido, que tiene una longitud de 100\n",
        "      in_lat = layers.Input(shape=(100,))\n",
        "\n",
        "      # Partimos de una imagen de 7x7\n",
        "      n_nodes = 256 * 7 * 7\n",
        "      gen = layers.Dense(n_nodes)(in_lat)\n",
        "      gen = layers.LeakyReLU(alpha=0.2)(gen)\n",
        "      gen = layers.Reshape((7, 7, 256))(gen)\n",
        "\n",
        "      # Fusión de las dos capas input\n",
        "      merge = layers.Concatenate()([gen, li])\n",
        "\n",
        "      # Escala tamaño al formato 14x14\n",
        "      gen = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
        "      gen = layers.LeakyReLU(alpha=0.2)(gen)\n",
        "      # Escala tamaño al formato 28x28\n",
        "      gen = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
        "      gen = layers.LeakyReLU(alpha=0.2)(gen)\n",
        "      # Capa de salida de la imagen de 28x28x1\n",
        "      out_layer = layers.Conv2DTranspose(1, (7,7), activation='tanh', padding='same')(gen)\n",
        "\n",
        "      model = Model([in_lat, in_label], out_layer)\n",
        "\n",
        "      return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyWgG09LCSJl"
      },
      "source": [
        "Utiliza el generador (aún sin entrenar) para crear una imágen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl7jcC7TdPTG"
      },
      "source": [
        "n_classes = 10\n",
        "generator = make_generator_model(n_classes)\n",
        "tf.keras.utils.plot_model(generator, show_shapes=True, to_file='generator.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYkHkk3wWg3e"
      },
      "source": [
        "#generator.summary()\n",
        "noise = tf.random.normal([1, 100])\n",
        "from numpy.random import randint\n",
        "noisy_label = randint(0, n_classes, 1)\n",
        "generated_image = generator([noise, noisy_label], training=False)\n",
        "plt.imshow((generated_image[0, :, :, 0] + 1) / 2, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0IKnaCtg6WE"
      },
      "source": [
        "### El discriminador\n",
        "\n",
        "El discriminador es un clasificador de imágenes basado en CNNs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw2tPLmk2pEP"
      },
      "source": [
        "def make_discriminator_model(n_classes):\n",
        "\n",
        "    #TODO: Haz tu propio discriminador\n",
        "    # Capa input para label\n",
        "    in_label = layers.Input(shape=(1,))\n",
        "    # Generar el embedding pata categorizar las label\n",
        "    li = layers.Embedding(n_classes, 50)(in_label)\n",
        "    # Generamos capa dense con tantas neuroans como dimensiones puede tener la imagen\n",
        "    n_nodes = 28*28*1\n",
        "    li = layers.Dense(n_nodes)(li)\n",
        "    # Se hace un reshape con las dimensiones de la imagen incluyendo el canal\n",
        "    li = layers.Reshape((28,28, 1))(li)\n",
        "\n",
        "    # Capa input para las imagenes\n",
        "    in_image = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    # Capa que concatena los dos inputs\n",
        "    merge = layers.Concatenate()([in_image, li])\n",
        "   \n",
        "    fe = layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
        "    fe = layers.LeakyReLU(alpha=0.2)(fe)\n",
        "    \n",
        "    fe = layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
        "    fe = layers.LeakyReLU(alpha=0.2)(fe)\n",
        "\n",
        "    # Aplana el mapa de características \n",
        "    fe = layers.Flatten()(fe)\n",
        "    \n",
        "    fe = layers.Dropout(0.4)(fe)\n",
        "\n",
        "    # Capa Dense de 1 neurona para hacer la discriminación Real o Fake\n",
        "    out_layer = layers.Dense(1)(fe)\n",
        "    \n",
        "    model = Model([in_image, in_label], out_layer)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WViQF8DTtsM"
      },
      "source": [
        "n_classes = 10\n",
        "discriminator = make_discriminator_model(n_classes)\n",
        "tf.keras.utils.plot_model(discriminator, show_shapes=True, to_file='discriminator.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhPneagzCaQv"
      },
      "source": [
        "Utiliza el discriminador (aún sin entrenar) para clasificar las imágenes como reales o fake. El modelo se entrenará para sacar valores positivos con imágenes reales y valores negativos con imágenes fake."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDkA05NE6QMs"
      },
      "source": [
        "#discriminator.summary()\n",
        "from numpy.random import randint\n",
        "label = randint(0, n_classes, 1)\n",
        "print(label)\n",
        "decision = discriminator([generated_image, label])\n",
        "print (decision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Definición de la función de coste y el optimizador\n",
        "\n",
        "Definimos la función de coste y los optimizadores para ambos modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psQfmXxYKU3X"
      },
      "source": [
        "# Este método devuelve una función helper para calcular cross entropy loss. \n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKY_iPSPNWoj"
      },
      "source": [
        "### Función de coste del Discriminador\n",
        "\n",
        "Este método cuantifica cuán bien el dicriminador es capaz de distinguir entre imágenes reales y falsas. Va a comparar las predicciones de imágenes reales con un array de 1s, y las predicciones de imágenes falsas con un array de 0s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkMNfBWlT-PV"
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd-3GCUEiKtv"
      },
      "source": [
        "### Coste del generador\n",
        "\n",
        "La función de coste del generador cuantifica cuán bien es capaz de engañar al discriminador. De forma intuitiva, si el generador funciona bien, el descriminador se equivocará. Aquí vamos a comparar las decisiones del discriminador en las imágenes falsas con un array de 1s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90BIcCKcDMxz"
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgIc7i0th_Iu"
      },
      "source": [
        "El discriminador y el generador tendrán optimizadores separados ya que vamos a entrenar las redes de forma separada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWCn_PVdEJZ7"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "metricsAcc=tf.keras.metrics.BinaryAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWtinsGDPJlV"
      },
      "source": [
        "### Guardar checkpoints\n",
        "\n",
        "Este notebook también demuestra cómo guardar y recuperar modelos, lo que puede ser muy útil en caso de que el entrenamiento se pause o queramos utilizarlo a posteriori."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA1w-7s2POEy"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Definiendo el bucle de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS2GWywBbAWo"
      },
      "source": [
        "noise_dim = 100\n",
        "num_examples_to_generate = 100\n",
        "\n",
        "# Vamos a reutilizar esta semilla para visualizar mejor el progreso en el GIF.\n",
        "from numpy import asarray\n",
        "seed_images = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "seed_labels = asarray([x for _ in range(10) for x in range(10)])\n",
        "print(seed_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jylSonrqSWfi"
      },
      "source": [
        "El bucle de entrenamiento comienza con el generador recibiendo una semilla aleatoria como entrada. Esta semilla se usa para producir una imagen. El discriminador se utiliza después para clasificar imágenes reales (del dataset) e imágenes falsas (producidas por el generador). El coste se calcula para cada una de las redes por separado y se actualizan los pesos mediante descenso por gradiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t5ibNo05jCB"
      },
      "source": [
        "# Aquí utilizamos `tf.function`\n",
        "# Esto hace que la función se \"compile\".\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    noise_image = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "    noise_labels = label = randint(0, n_classes, BATCH_SIZE)\n",
        "    #print(\"coming into the function\")\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "      real_output = discriminator([images, labels], training=True)\n",
        "      #print(\"salida con imagenes reales {:.5f}\".format(tf.math.reduce_mean(real_output)))\n",
        "      generated_images = generator([noise_image, noise_labels], training=True)\n",
        "      fake_output = discriminator([generated_images, noise_labels], training=True)\n",
        "      #print(\"salida con imagenes falsas {:.5f}\".format(tf.math.reduce_mean(fake_output)))\n",
        "      \n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "      \n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M7LmLtGEMQJ"
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    j = 0\n",
        "    for image_batch, label_batch in dataset:\n",
        "      #print(j)\n",
        "      train_step(image_batch, label_batch)\n",
        "      #j = j + 1\n",
        "\n",
        "    print(\"A NEW EPOCH\")\n",
        "\n",
        "    # Producimos imágenes para el GIF sobre la marcha\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epoch + 1, seed_images, seed_labels)\n",
        "\n",
        "    # Guardamos el modelo cada 15 épocas\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generación tras cada época\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator, epochs, seed_images, seed_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aFF7Hk3XdeW"
      },
      "source": [
        "**Generación y guardado de imágenes**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmdVsmvhPxyy"
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input_images, test_input_labels):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model([test_input_images, test_input_labels], training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(10, 10, i+1)\n",
        "      # scale [-1, 1] to [0, 1]\n",
        "      image = (predictions[i, :, :, 0] + 1.0) / 2.0\n",
        "      plt.imshow(image, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZrd4CdjR-Fp"
      },
      "source": [
        "## Entrenamos el modelo\n",
        "\n",
        "Llamamos a la función `train()` definida anteriormente para enrtenar el generador y el discriminador de forma simultanea. Entrenar GANs es complejo, es importante que el generador y el discriminador no aventajen mucho al adversario (ambos deberían entrenar a un ritmo parecido).\n",
        "\n",
        "Al principio del entrenamiento, las imágenes generadas van a parecer ruido aleatorio. A medida que el entrenamiento progrese, los dígitos generados irán pareciendo cada vez más reales. Tras unas 50 épocas, ya son como dígitos de MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly3UN0SLLY2l"
      },
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 100\n",
        "train_dataset_shuffled = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train(train_dataset_shuffled, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfM4YcPVPkNO"
      },
      "source": [
        "Recuperamos el último checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhXsd0srPo8c"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4M_vIbUi7c0"
      },
      "source": [
        "## Creación del GIF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfO5wCdclHGL"
      },
      "source": [
        "# Muestra de una imágen según el número de época\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x3q9_Oe5q0A"
      },
      "source": [
        "display_image(EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywiH3nL8guF"
      },
      "source": [
        "Usamos `imageio` para crear un gif animado con estas imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGKQgENQ8lEI"
      },
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGhC3-fMWSwl"
      },
      "source": [
        "Si estás trabajando en Colab, puedes descargar la animación con el siguiente código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV0yiKpzNP1b"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}