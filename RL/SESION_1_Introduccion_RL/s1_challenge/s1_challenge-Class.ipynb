{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mioti.png\" style=\"height: 100px\">\n",
    "<center style=\"color:#888\">Módulo Advanced Data Science<br/>Asignatura Reinforcement Learning</center>\n",
    "\n",
    "# Challenge S1: Práctica con Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-11T16:37:47.015588Z",
     "start_time": "2021-11-11T16:37:47.010704Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install gym\n",
    "# !pip install pyglet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:41:01.646041Z",
     "start_time": "2021-11-12T10:41:00.315993Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from s1_utils import env_wrapper\n",
    "# from IPython import display\n",
    "# import os\n",
    "# os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El principal **objetivo** de esta práctica es sentirnos cómodos utilizando el framework Gym para manejar entornos de problemas de Reinforcement Learning.\n",
    "\n",
    "El el worksheet ya hemos visto el entorno MountainCar de OpenAI Gym. Ahora, buscándote la vida, debes obtener una lista llamada env_names con todos los entornos que contiene la librería e imprimirla a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:41:06.198068Z",
     "start_time": "2021-11-12T10:41:06.183258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acrobot-v1\n",
      "Ant-v2\n",
      "Ant-v3\n",
      "BipedalWalker-v3\n",
      "BipedalWalkerHardcore-v3\n",
      "Blackjack-v1\n",
      "CarRacing-v0\n",
      "CartPole-v0\n",
      "CartPole-v1\n",
      "CliffWalking-v0\n",
      "CubeCrash-v0\n",
      "CubeCrashScreenBecomesBlack-v0\n",
      "CubeCrashSparse-v0\n",
      "FetchPickAndPlace-v1\n",
      "FetchPickAndPlaceDense-v1\n",
      "FetchPush-v1\n",
      "FetchPushDense-v1\n",
      "FetchReach-v1\n",
      "FetchReachDense-v1\n",
      "FetchSlide-v1\n",
      "FetchSlideDense-v1\n",
      "FrozenLake-v1\n",
      "FrozenLake8x8-v1\n",
      "HalfCheetah-v2\n",
      "HalfCheetah-v3\n",
      "HandManipulateBlock-v0\n",
      "HandManipulateBlockDense-v0\n",
      "HandManipulateBlockFull-v0\n",
      "HandManipulateBlockFullDense-v0\n",
      "HandManipulateBlockRotateParallel-v0\n",
      "HandManipulateBlockRotateParallelDense-v0\n",
      "HandManipulateBlockRotateParallelTouchSensors-v0\n",
      "HandManipulateBlockRotateParallelTouchSensors-v1\n",
      "HandManipulateBlockRotateParallelTouchSensorsDense-v0\n",
      "HandManipulateBlockRotateParallelTouchSensorsDense-v1\n",
      "HandManipulateBlockRotateXYZ-v0\n",
      "HandManipulateBlockRotateXYZDense-v0\n",
      "HandManipulateBlockRotateXYZTouchSensors-v0\n",
      "HandManipulateBlockRotateXYZTouchSensors-v1\n",
      "HandManipulateBlockRotateXYZTouchSensorsDense-v0\n",
      "HandManipulateBlockRotateXYZTouchSensorsDense-v1\n",
      "HandManipulateBlockRotateZ-v0\n",
      "HandManipulateBlockRotateZDense-v0\n",
      "HandManipulateBlockRotateZTouchSensors-v0\n",
      "HandManipulateBlockRotateZTouchSensors-v1\n",
      "HandManipulateBlockRotateZTouchSensorsDense-v0\n",
      "HandManipulateBlockRotateZTouchSensorsDense-v1\n",
      "HandManipulateBlockTouchSensors-v0\n",
      "HandManipulateBlockTouchSensors-v1\n",
      "HandManipulateBlockTouchSensorsDense-v0\n",
      "HandManipulateBlockTouchSensorsDense-v1\n",
      "HandManipulateEgg-v0\n",
      "HandManipulateEggDense-v0\n",
      "HandManipulateEggFull-v0\n",
      "HandManipulateEggFullDense-v0\n",
      "HandManipulateEggRotate-v0\n",
      "HandManipulateEggRotateDense-v0\n",
      "HandManipulateEggRotateTouchSensors-v0\n",
      "HandManipulateEggRotateTouchSensors-v1\n",
      "HandManipulateEggRotateTouchSensorsDense-v0\n",
      "HandManipulateEggRotateTouchSensorsDense-v1\n",
      "HandManipulateEggTouchSensors-v0\n",
      "HandManipulateEggTouchSensors-v1\n",
      "HandManipulateEggTouchSensorsDense-v0\n",
      "HandManipulateEggTouchSensorsDense-v1\n",
      "HandManipulatePen-v0\n",
      "HandManipulatePenDense-v0\n",
      "HandManipulatePenFull-v0\n",
      "HandManipulatePenFullDense-v0\n",
      "HandManipulatePenRotate-v0\n",
      "HandManipulatePenRotateDense-v0\n",
      "HandManipulatePenRotateTouchSensors-v0\n",
      "HandManipulatePenRotateTouchSensors-v1\n",
      "HandManipulatePenRotateTouchSensorsDense-v0\n",
      "HandManipulatePenRotateTouchSensorsDense-v1\n",
      "HandManipulatePenTouchSensors-v0\n",
      "HandManipulatePenTouchSensors-v1\n",
      "HandManipulatePenTouchSensorsDense-v0\n",
      "HandManipulatePenTouchSensorsDense-v1\n",
      "HandReach-v0\n",
      "HandReachDense-v0\n",
      "Hopper-v2\n",
      "Hopper-v3\n",
      "Humanoid-v2\n",
      "Humanoid-v3\n",
      "HumanoidStandup-v2\n",
      "InvertedDoublePendulum-v2\n",
      "InvertedPendulum-v2\n",
      "LunarLander-v2\n",
      "LunarLanderContinuous-v2\n",
      "MemorizeDigits-v0\n",
      "MountainCar-v0\n",
      "MountainCarContinuous-v0\n",
      "Pendulum-v1\n",
      "Pusher-v2\n",
      "Reacher-v2\n",
      "Striker-v2\n",
      "Swimmer-v2\n",
      "Swimmer-v3\n",
      "Taxi-v3\n",
      "Thrower-v2\n",
      "Walker2d-v2\n",
      "Walker2d-v3\n"
     ]
    }
   ],
   "source": [
    "from gym import envs\n",
    "\n",
    "env_names = [env.id for env in envs.registry.all()] ## YOUR CODE HERE ##\n",
    "for name in sorted(env_names):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación escribe una función que visualice el entorno que más te guste de *env_names* (argumento de la función), ejecute 250 steps y si consigue finalizarlo imprima un mesaje de enhorabuna con el número de steps que ha necesitado para llegar al final y la reconpensa acumulada final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:41:11.513201Z",
     "start_time": "2021-11-12T10:41:11.504384Z"
    }
   },
   "outputs": [],
   "source": [
    "def render_env(myenv):\n",
    "    ## YOUR CODE HERE ##\n",
    "    steps = 250\n",
    "    observation = myenv.reset()\n",
    "    # al empezar, tomamos la observación anterior como la primera\n",
    "    previous_observation = observation\n",
    "\n",
    "    # Ejecutamos 250 pasos en el entorno\n",
    "    try:\n",
    "        for step in range(steps):\n",
    "        # Visualizamos el juego de MountainCar\n",
    "            myenv.render()\n",
    "\n",
    "            # Tomamos una acción aleatoriamente\n",
    "            action = myenv.action_space.sample()\n",
    "\n",
    "            # Ejecutamos la acción\n",
    "            observation, reward, done, info = myenv.step(action) \n",
    "            \n",
    "             ## Si se ha llegado al objetivo done = True y por lo tanto se corta el juego. Hacemos break paa salir del bucle.\n",
    "            if done:\n",
    "                print(f'Enhorabuena! Lo has logrado en {step} pasos')\n",
    "                break\n",
    "            \n",
    "        ## Hemos salido del bucle ejecutanto los pasos máximos establecidos y no lo hemos conseguido.\n",
    "        else:\n",
    "            print(f'Lo siento! No has alcanzado el objetivo')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    finally:\n",
    "        myenv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:41:19.254281Z",
     "start_time": "2021-11-12T10:41:14.215740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento! No has alcanzado el objetivo\n"
     ]
    }
   ],
   "source": [
    "render_env(gym.make(\"Pendulum-v1\").unwrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `env_wrapper`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenta qué hace cada parte del código de la función en las líneas con `##`. Es decir, completa los comentarios de la función `env_wrapper`, explicando qué hace cada uno de los métodos usados sobre `env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:48:14.554964Z",
     "start_time": "2021-11-12T10:48:14.546182Z"
    }
   },
   "outputs": [],
   "source": [
    "def env_wrapper(policy_func, env,steps):\n",
    "    '''\n",
    "    Simula el entorno `env` siguiendo la política `policy_func`.\n",
    "    '''\n",
    "    ## Resetea el entorno y devuelve la observación inicial\n",
    "    observation = env.reset()\n",
    "    # al empezar, tomamos la observación anterior como la primera\n",
    "    previous_observation = observation\n",
    "\n",
    "    # Ejecutamos 250 pasos en el entorno\n",
    "    try:\n",
    "        for step in range(steps):\n",
    "            ## Visulizamos en una ventana el estado actual del entorno.\n",
    "            env.render()\n",
    "\n",
    "            ## Determina que accion tomar. Esta acción dependerá de la politica que hayamos considerado para el entorno\n",
    "            ## podría ser aleatoria, determinista y probabilistica\n",
    "            action = policy_func(observation, step, previous_observation)\n",
    "#             print(f'wrapper action {action}')\n",
    "            # actualizamos previous_observation\n",
    "            previous_observation = observation\n",
    "            \n",
    "            ## ejecuta la acción previamnte calculada y nos devuelve una nueva observación (obsrrvation),\n",
    "            ## una recompensa (reward), si el entorno ha llegado al obetivo (done), e información adicional\n",
    "            observation, reward, done, info = env.step(action)\n",
    "           ## Si se ha llegado al objetivo done = True y por lo tanto se corta el juego. Hacemos break paa salir del bucle.\n",
    "            if done:\n",
    "                print(f'Enhorabuena! Lo has logrado en {step} pasos')\n",
    "                break\n",
    "                \n",
    "            \n",
    "         ## Hemos salido del bucle ejecutanto los pasos máximos establecidos y no lo hemos conseguido. \n",
    "        else:\n",
    "            print(f'Lo siento! No has alcanzado el objetivo')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    finally:\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprendiendo los espacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:48:18.681953Z",
     "start_time": "2021-11-12T10:48:18.675119Z"
    }
   },
   "outputs": [],
   "source": [
    "# unwrapped evita que tenga un limite temporal de 200\n",
    "env = gym.make(\"MountainCar-v0\").unwrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, retomaremos el ejemplo del entorno *MountainCar* (https://github.com/openai/gym/wiki/MountainCar-v0) presentado durante el [Worksheet](./s1_worksheet.ipynb). En este, se probó a utilizar una política aleatoria que apenas conseguía mover el coche desde su posición inicial y que no utilizaba ningún dato del estado del entorno para moverse. \n",
    "\n",
    "Para solucionar esto, durante el challenge vamos a aplicar distintas formas de observar el entorno y así conseguir optimizarlo. Hemos creado una función, `env_wrapper` que simula la interacción del agente con un entorno dado por `env`, dada una función de política."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargado el entorno, vemos que no tiene un estado definido por defecto. Es necesario aplicar el método `.reset()` para que el agente tenga definido un estado.\n",
    "\n",
    "En este caso, el estado viene dado por un array con dos variables, la posición y la velocidad. Que como podemos observar, empieza cerca de la posición -0.56 y con velocidad nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:48:22.089419Z",
     "start_time": "2021-11-12T10:48:22.082579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0 = [-0.5611406  0.       ]\n",
      "env.state = [-0.56114059  0.        ]\n"
     ]
    }
   ],
   "source": [
    "s0 = env.reset()\n",
    "print(f's0 = {s0}')\n",
    "print(f'env.state = {env.state}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a ver una descripción del espacio de estados y de acciones ¡¡Prueba con otro juego de la lista!!. Observa los resultados. *Nota:* Algunos juegos pueden dar error en el SO Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:48:24.924829Z",
     "start_time": "2021-11-12T10:48:24.913101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espacio de estados:\n",
      "Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "\n",
      " Cota inferior;  [-1.2  -0.07]\n",
      "\n",
      " Cota superior;  [0.6  0.07]\n",
      "Espacio de acciones: \n",
      "Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "from gym.spaces import *\n",
    "\n",
    "def print_spaces(space):\n",
    "    print(space)\n",
    "    if isinstance(space, Box): # Comprueba si el space es de tipo box, imprime las fronteras\n",
    "           print ('\\n Cota inferior; ', space.low)\n",
    "           print ('\\n Cota superior; ', space.high) \n",
    "           \n",
    "\n",
    "environment = gym.make('MountainCar-v0')\n",
    "print('Espacio de estados:')\n",
    "print_spaces(environment.observation_space)\n",
    "print('Espacio de acciones: ')\n",
    "print_spaces(environment.action_space)\n",
    "try:\n",
    "    print('Descripcion de las acciones. ', environment.unwrapped.get_action_meanings())\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprendidos los espacios de estados y acciones, ahora como ejemplo de cómo utilizar `env_wrapper`, vamos a utiliar una polítca que siempre toma la acción de impulsar hacia la izquierda. \n",
    "\n",
    "Como puedes observar, esta política no es suficientemente inteligente para poder alcanzar la meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:48:45.201199Z",
     "start_time": "2021-11-12T10:48:28.105129Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython import display\n",
    "\n",
    "import gym \n",
    "env = gym.make(\"MountainCar-v0\").unwrapped\n",
    "env.reset()\n",
    "for _ in range(1000): \n",
    "    env.render() \n",
    "    env.step(env.action_space.sample()) # take a random action \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:48:53.295816Z",
     "start_time": "2021-11-12T10:48:48.083174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento! No has alcanzado el objetivo\n"
     ]
    }
   ],
   "source": [
    "steps = 300\n",
    "def dummy_policy(observarion, *args):\n",
    "    return 0\n",
    "env_wrapper(dummy_policy, env, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy determinista\n",
    "\n",
    "En primer lugar implementa una función determinista que consiga lograr el objetivo de permitir al coche alcanzar la meta superior derecha. Para ello, implementamos una función que recibe la observación actual del entorno y el contador de iteraciones ejecutadas, y devuelve la acción a ejecutar.\n",
    "\n",
    "Recuerda, las acciones posibles son:\n",
    "* 0: impulsar a la izquierda\n",
    "* 1: no hacer nada\n",
    "* 2: impulsar a la derecha\n",
    "\n",
    "**Tip:** The optimal policy is to move on the left accumulating inertia and then to push as much as possible to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:48:57.246976Z",
     "start_time": "2021-11-12T10:48:57.240150Z"
    }
   },
   "outputs": [],
   "source": [
    "def policy_determinista(observation, step, *args):\n",
    "    x, v = observation    \n",
    "    print('Step: '+str(step),'x:',x,' v:',v)    \n",
    "    \n",
    "    # ESCRIBE TU CÓDIGO\n",
    "    \n",
    "    action=0 if v < 0 and x < 0 else 2\n",
    "       \n",
    "    return action \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:49:02.367371Z",
     "start_time": "2021-11-12T10:49:00.105182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 x: -0.45117584  v: 0.0\n",
      "Step: 1 x: -0.45071474  v: 0.00046109132\n",
      "Step: 2 x: -0.44979593  v: 0.0009188063\n",
      "Step: 3 x: -0.44842613  v: 0.0013697963\n",
      "Step: 4 x: -0.44661537  v: 0.0018107684\n",
      "Step: 5 x: -0.44437686  v: 0.0022385118\n",
      "Step: 6 x: -0.44172692  v: 0.0026499252\n",
      "Step: 7 x: -0.43868488  v: 0.0030420418\n",
      "Step: 8 x: -0.43527284  v: 0.0034120532\n",
      "Step: 9 x: -0.4315155  v: 0.0037573336\n",
      "Step: 10 x: -0.42744005  v: 0.0040754597\n",
      "Step: 11 x: -0.42307582  v: 0.00436423\n",
      "Step: 12 x: -0.41845414  v: 0.0046216836\n",
      "Step: 13 x: -0.413608  v: 0.004846111\n",
      "Step: 14 x: -0.40857196  v: 0.005036069\n",
      "Step: 15 x: -0.40338156  v: 0.0051903883\n",
      "Step: 16 x: -0.39807338  v: 0.0053081783\n",
      "Step: 17 x: -0.39268455  v: 0.0053888313\n",
      "Step: 18 x: -0.38725254  v: 0.005432022\n",
      "Step: 19 x: -0.38181484  v: 0.0054377033\n",
      "Step: 20 x: -0.37640873  v: 0.0054061\n",
      "Step: 21 x: -0.37107104  v: 0.005337701\n",
      "Step: 22 x: -0.36583778  v: 0.0052332478\n",
      "Step: 23 x: -0.36074406  v: 0.0050937207\n",
      "Step: 24 x: -0.35582373  v: 0.0049203243\n",
      "Step: 25 x: -0.35110927  v: 0.004714472\n",
      "Step: 26 x: -0.3466315  v: 0.0044777677\n",
      "Step: 27 x: -0.3424195  v: 0.0042119897\n",
      "Step: 28 x: -0.33850044  v: 0.003919072\n",
      "Step: 29 x: -0.33489934  v: 0.0036010868\n",
      "Step: 30 x: -0.3316391  v: 0.003260229\n",
      "Step: 31 x: -0.32874033  v: 0.0028987986\n",
      "Step: 32 x: -0.32622114  v: 0.0025191852\n",
      "Step: 33 x: -0.32409728  v: 0.002123855\n",
      "Step: 34 x: -0.32238194  v: 0.0017153361\n",
      "Step: 35 x: -0.32108572  v: 0.0012962071\n",
      "Step: 36 x: -0.32021666  v: 0.00086908543\n",
      "Step: 37 x: -0.31978002  v: 0.00043661686\n",
      "Step: 38 x: -0.31977856  v: 1.4657336e-06\n",
      "Step: 39 x: -0.32021227  v: -0.0004336944\n",
      "Step: 40 x: -0.32307845  v: -0.00286619\n",
      "Step: 41 x: -0.32835945  v: -0.0052810153\n",
      "Step: 42 x: -0.33602247  v: -0.0076630097\n",
      "Step: 43 x: -0.34601924  v: -0.00999675\n",
      "Step: 44 x: -0.35828573  v: -0.012266486\n",
      "Step: 45 x: -0.37274185  v: -0.0144561315\n",
      "Step: 46 x: -0.38929117  v: -0.016549328\n",
      "Step: 47 x: -0.40782076  v: -0.0185296\n",
      "Step: 48 x: -0.42820135  v: -0.02038058\n",
      "Step: 49 x: -0.4502877  v: -0.022086335\n",
      "Step: 50 x: -0.47391942  v: -0.023631746\n",
      "Step: 51 x: -0.4989224  v: -0.025002964\n",
      "Step: 52 x: -0.52511024  v: -0.026187867\n",
      "Step: 53 x: -0.5522868  v: -0.027176531\n",
      "Step: 54 x: -0.5802484  v: -0.027961636\n",
      "Step: 55 x: -0.60878724  v: -0.028538806\n",
      "Step: 56 x: -0.63769406  v: -0.028906824\n",
      "Step: 57 x: -0.66676176  v: -0.029067721\n",
      "Step: 58 x: -0.6957885  v: -0.029026706\n",
      "Step: 59 x: -0.72458047  v: -0.028791957\n",
      "Step: 60 x: -0.7529547  v: -0.028374279\n",
      "Step: 61 x: -0.7807414  v: -0.027786665\n",
      "Step: 62 x: -0.80778515  v: -0.027043765\n",
      "Step: 63 x: -0.8339465  v: -0.026161348\n",
      "Step: 64 x: -0.85910225  v: -0.025155742\n",
      "Step: 65 x: -0.8831456  v: -0.024043314\n",
      "Step: 66 x: -0.9059856  v: -0.022840023\n",
      "Step: 67 x: -0.9275466  v: -0.021561023\n",
      "Step: 68 x: -0.94776696  v: -0.02022036\n",
      "Step: 69 x: -0.96659774  v: -0.01883076\n",
      "Step: 70 x: -0.9840012  v: -0.017403489\n",
      "Step: 71 x: -0.9999495  v: -0.015948284\n",
      "Step: 72 x: -1.0144229  v: -0.014473356\n",
      "Step: 73 x: -1.0274082  v: -0.012985431\n",
      "Step: 74 x: -1.0388981  v: -0.011489836\n",
      "Step: 75 x: -1.0488887  v: -0.00999061\n",
      "Step: 76 x: -1.0573794  v: -0.0084906425\n",
      "Step: 77 x: -1.0643712  v: -0.006991809\n",
      "Step: 78 x: -1.0698663  v: -0.005495126\n",
      "Step: 79 x: -1.0738672  v: -0.004000905\n",
      "Step: 80 x: -1.0763761  v: -0.0025089025\n",
      "Step: 81 x: -1.0773946  v: -0.0010184743\n",
      "Step: 82 x: -1.0769234  v: 0.0004712742\n",
      "Step: 83 x: -1.0729619  v: 0.00396134\n",
      "Step: 84 x: -1.0655081  v: 0.007453876\n",
      "Step: 85 x: -1.054558  v: 0.010950105\n",
      "Step: 86 x: -1.0401084  v: 0.014449496\n",
      "Step: 87 x: -1.0221596  v: 0.017948931\n",
      "Step: 88 x: -1.0007176  v: 0.02144188\n",
      "Step: 89 x: -0.9758001  v: 0.024917616\n",
      "Step: 90 x: -0.9474396  v: 0.028360486\n",
      "Step: 91 x: -0.91569024  v: 0.031749364\n",
      "Step: 92 x: -0.88063294  v: 0.035057314\n",
      "Step: 93 x: -0.8423813  v: 0.03825164\n",
      "Step: 94 x: -0.8010869  v: 0.041294366\n",
      "Step: 95 x: -0.7569436  v: 0.04414335\n",
      "Step: 96 x: -0.7101896  v: 0.046753958\n",
      "Step: 97 x: -0.66110814  v: 0.04908144\n",
      "Step: 98 x: -0.6100244  v: 0.05108376\n",
      "Step: 99 x: -0.5572997  v: 0.05272471\n",
      "Step: 100 x: -0.50332266  v: 0.05397704\n",
      "Step: 101 x: -0.4484976  v: 0.05482506\n",
      "Step: 102 x: -0.39323103  v: 0.055266555\n",
      "Step: 103 x: -0.3379175  v: 0.055313535\n",
      "Step: 104 x: -0.28292567  v: 0.054991834\n",
      "Step: 105 x: -0.2285861  v: 0.05433958\n",
      "Step: 106 x: -0.17518134  v: 0.053404734\n",
      "Step: 107 x: -0.122939244  v: 0.052242108\n",
      "Step: 108 x: -0.072029024  v: 0.05091022\n",
      "Step: 109 x: -0.022560664  v: 0.04946836\n",
      "Step: 110 x: 0.025413422  v: 0.047974084\n",
      "Step: 111 x: 0.07189477  v: 0.04648135\n",
      "Step: 112 x: 0.11693404  v: 0.04503927\n",
      "Step: 113 x: 0.16062556  v: 0.043691527\n",
      "Step: 114 x: 0.20310178  v: 0.04247621\n",
      "Step: 115 x: 0.24452788  v: 0.041426096\n",
      "Step: 116 x: 0.28509703  v: 0.04056915\n",
      "Step: 117 x: 0.32502618  v: 0.03992915\n",
      "Step: 118 x: 0.36455256  v: 0.03952639\n",
      "Step: 119 x: 0.40393087  v: 0.039378293\n",
      "Step: 120 x: 0.4434308  v: 0.039499942\n",
      "Step: 121 x: 0.48333526  v: 0.03990446\n",
      "Enhorabuena! Lo has logrado en 121 pasos\n"
     ]
    }
   ],
   "source": [
    "steps = 250\n",
    "env_wrapper(policy_determinista, env, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy probabilista\n",
    "\n",
    "¿Se te ocurre alguna manera de convertir la política anterior a un enfoque probabilístico?\n",
    "\n",
    "**Ayuda:** Puedes seguir una estrategia tipo $\\epsilon$-greedy como se describe [aquí](https://es.wikipedia.org/wiki/Aprendizaje_por_refuerzo#Exploraci%C3%B3n). \n",
    "Es decir, puedes convertir la política anterior a una probabilística diciéndole que un porcentaje de los casos realice una acción al azar en lugar de determinista. En este caso, **¿qué pasa si aumentas la probabilidad de realizar acciones al azar?**. Puedes leer una breve introducción sobre este algoritmo y su importancia en Reinforcement Learning en [link](https://medium.com/analytics-vidhya/the-epsilon-greedy-algorithm-for-reinforcement-learning-5fe6f96dc870).\n",
    "\n",
    "Puedes crear un función probabilística que siga la política $\\epsilon$-greedy, es decir, según esta política puedes coger una acción aleatoria o la acción determinista correspondiente calculada en el apartado anterior.  **No olvides** incluir los parámetros referentes a épsilon como argumentos en las funciones que correspondan ni contestar a la pregunta. Si tienes que modificar el wrapper anterior no olvides hacerte una **copia** de la función y **renombrarlo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**\n",
    "* Siguiendo la sugerencia hemos implementado una estrategia e-gredy con descenso del valor de epsilon. Esta estrategía está muy extendida en el ámbito del RL además de ser relativamente sencilla de implementar. \n",
    "* Por lo que he podio validar en as pruebas que he realizado contra más alto es epsilon y **más cercano es a 1 la política que con más frecuencia  se eligirá será la Aleatoria** con más probabilidad de no conseguir exito y de ternlo en mayor número de pasos. Por contra contra **más cercano sea al 0 la política más frecuente será la Determinista** y por lo tanto con más probabilidad de conseguir éxito y en menor número de pasos. He realizado dos ejemplos uno con un epsilon=1 y otro con epsilon=0.25 y se demuestra que el de 0,25 que tiene menos probabilidad de tomar acciones al azar llega antes a tener éxito, encontra del inicializado a 1 que si llega al exito es apurando al máxmimo el número de pasos, existiendo ocasiones en las que no llega a éxito. **En conclusión** a mayor probabilidad de tomar acciones al azar mayor riesgo de no alcanzar el objetivo.\n",
    "* También comentar que he visto distintas estrategias para hacer la degradación del epsilon y me he quedado con **epsilon-=EPSILON_DECAY**, otra que también he podido observar es **epsilon*=(1-EPSILON_DECAY)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:49:12.112674Z",
     "start_time": "2021-11-12T10:49:12.098026Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # Puedes usar el método random de numpy para elegir una acción aleatoria\n",
    "\n",
    "def env_wrapper_probabilistico(policy_func, env,steps,myepsilon=1.0):\n",
    "    '''\n",
    "    Simula el entorno `env` siguiendo la política `policy_func`.\n",
    "    '''\n",
    "    steps = 250 \n",
    "    EPSILON_MIN = 0.05 ## YOUR CODE HERE ##\n",
    "    EPSILON_DECAY = (1-EPSILON_MIN) / steps\n",
    "    epsilon = myepsilon\n",
    "    \n",
    "    ## Resetea el entorno y devuelve la observación inicial\n",
    "    observation = env.reset()\n",
    "    # al empezar, tomamos la observación anterior como la primera\n",
    "    previous_observation = observation\n",
    "\n",
    "    # Ejecutamos 250 pasos en el entorno\n",
    "    try:\n",
    "        for step in range(steps):\n",
    "            ## Visulizamos en una ventana el estado actual del entorno.\n",
    "            env.render()\n",
    "\n",
    "            ## Determina que accion tomar. Esta acción dependerá de la politica que hayamos considerado para el entorno\n",
    "            ## podría ser aleatoria, determinista y probabilistica\n",
    "            action = policy_func(observation, step, previous_observation,env,epsilon)\n",
    "#             print(f'wrapper action {action}')\n",
    "            # actualizamos previous_observation\n",
    "            previous_observation = observation\n",
    "            \n",
    "            ## ejecuta la acción previamnte calculada y nos devuelve una nueva observación (obsrrvation),\n",
    "            ## una recompensa (reward), si el entorno ha llegado al obetivo (done), e información adicional\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            ## Si se ha llegado al objetivo done = True y por lo tanto se corta el juego. Hacemos break paa salir del bucle.\n",
    "            if done:\n",
    "                print(f'Enhorabuena! Lo has logrado en {step} pasos')\n",
    "                break\n",
    "                \n",
    "            # Reducimos el epsilon hasta que llege al mínimo. Lo hacemos con ua resta\n",
    "            if epsilon >= EPSILON_MIN:\n",
    "                epsilon -= EPSILON_DECAY    \n",
    "            \n",
    "        ## Hemos salido del bucle ejecutanto los pasos máximos establecidos y no lo hemos conseguido. \n",
    "        else:\n",
    "            print(f'Lo siento! No has alcanzado el objetivo')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    finally:\n",
    "        env.close()\n",
    "\n",
    "def policy_probabilista(observation, step, *args):\n",
    "    \n",
    "    # YOUR CODE HERE #\n",
    "    \n",
    "    #Calculo valor de epsilom\n",
    "    #calculo numero aletorio\n",
    "    #ver si es mayor o menor que epsilosn\n",
    "    # si mayor llamar a policy_determinista.\n",
    "    #si menor llamar a politica aleatoria env.action_s\n",
    "    #Obtenemos el modelo que lo hemos pasado en los args provinientte de la función env_wrapper\n",
    "    \n",
    "    myenv=args[1]\n",
    "    myepsilon=args[2]\n",
    "    p = np.random.uniform(0, 1)\n",
    "    print(f'Step: {step} Número Aleatorio: {p} Epsilon: {myepsilon}')\n",
    "   \n",
    "    if (p < myepsilon):\n",
    "        action = myenv.action_space.sample()\n",
    "        print(f'Step: {step} Política Aleatoria - Accion {action}')\n",
    "\n",
    "    else:\n",
    "        action = policy_determinista(observation, step)\n",
    "        print(f'Step: {step} Política Determinista - Accion {action}')\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:49:59.525932Z",
     "start_time": "2021-11-12T10:49:55.389411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Número Aleatorio: 0.90117591438294 Epsilon: 1.0\n",
      "Step: 0 Política Aleatoria - Accion 1\n",
      "Step: 1 Número Aleatorio: 0.8684455106131134 Epsilon: 0.9962\n",
      "Step: 1 Política Aleatoria - Accion 2\n",
      "Step: 2 Número Aleatorio: 0.09321372222083957 Epsilon: 0.9924\n",
      "Step: 2 Política Aleatoria - Accion 0\n",
      "Step: 3 Número Aleatorio: 0.16364969136445706 Epsilon: 0.9885999999999999\n",
      "Step: 3 Política Aleatoria - Accion 0\n",
      "Step: 4 Número Aleatorio: 0.9548017731134211 Epsilon: 0.9847999999999999\n",
      "Step: 4 Política Aleatoria - Accion 1\n",
      "Step: 5 Número Aleatorio: 0.6169686465541068 Epsilon: 0.9809999999999999\n",
      "Step: 5 Política Aleatoria - Accion 2\n",
      "Step: 6 Número Aleatorio: 0.6733141926659242 Epsilon: 0.9771999999999998\n",
      "Step: 6 Política Aleatoria - Accion 0\n",
      "Step: 7 Número Aleatorio: 0.11132901416862861 Epsilon: 0.9733999999999998\n",
      "Step: 7 Política Aleatoria - Accion 0\n",
      "Step: 8 Número Aleatorio: 0.16536635224553176 Epsilon: 0.9695999999999998\n",
      "Step: 8 Política Aleatoria - Accion 1\n",
      "Step: 9 Número Aleatorio: 0.552776460161345 Epsilon: 0.9657999999999998\n",
      "Step: 9 Política Aleatoria - Accion 2\n",
      "Step: 10 Número Aleatorio: 0.8649146809308678 Epsilon: 0.9619999999999997\n",
      "Step: 10 Política Aleatoria - Accion 1\n",
      "Step: 11 Número Aleatorio: 0.6394871984650385 Epsilon: 0.9581999999999997\n",
      "Step: 11 Política Aleatoria - Accion 1\n",
      "Step: 12 Número Aleatorio: 0.23203059292678274 Epsilon: 0.9543999999999997\n",
      "Step: 12 Política Aleatoria - Accion 1\n",
      "Step: 13 Número Aleatorio: 0.41443885023423266 Epsilon: 0.9505999999999997\n",
      "Step: 13 Política Aleatoria - Accion 1\n",
      "Step: 14 Número Aleatorio: 0.09654985189481835 Epsilon: 0.9467999999999996\n",
      "Step: 14 Política Aleatoria - Accion 1\n",
      "Step: 15 Número Aleatorio: 0.6161143432505307 Epsilon: 0.9429999999999996\n",
      "Step: 15 Política Aleatoria - Accion 0\n",
      "Step: 16 Número Aleatorio: 0.8401888676087242 Epsilon: 0.9391999999999996\n",
      "Step: 16 Política Aleatoria - Accion 0\n",
      "Step: 17 Número Aleatorio: 0.4333790733354367 Epsilon: 0.9353999999999996\n",
      "Step: 17 Política Aleatoria - Accion 2\n",
      "Step: 18 Número Aleatorio: 0.18204893015604762 Epsilon: 0.9315999999999995\n",
      "Step: 18 Política Aleatoria - Accion 1\n",
      "Step: 19 Número Aleatorio: 0.20486011235891055 Epsilon: 0.9277999999999995\n",
      "Step: 19 Política Aleatoria - Accion 2\n",
      "Step: 20 Número Aleatorio: 0.8517998831989073 Epsilon: 0.9239999999999995\n",
      "Step: 20 Política Aleatoria - Accion 1\n",
      "Step: 21 Número Aleatorio: 0.5381582033480307 Epsilon: 0.9201999999999995\n",
      "Step: 21 Política Aleatoria - Accion 0\n",
      "Step: 22 Número Aleatorio: 0.6240764482887906 Epsilon: 0.9163999999999994\n",
      "Step: 22 Política Aleatoria - Accion 1\n",
      "Step: 23 Número Aleatorio: 0.12568459226861606 Epsilon: 0.9125999999999994\n",
      "Step: 23 Política Aleatoria - Accion 1\n",
      "Step: 24 Número Aleatorio: 0.17833363438721384 Epsilon: 0.9087999999999994\n",
      "Step: 24 Política Aleatoria - Accion 1\n",
      "Step: 25 Número Aleatorio: 0.33559064930218063 Epsilon: 0.9049999999999994\n",
      "Step: 25 Política Aleatoria - Accion 0\n",
      "Step: 26 Número Aleatorio: 0.6769797869974291 Epsilon: 0.9011999999999993\n",
      "Step: 26 Política Aleatoria - Accion 1\n",
      "Step: 27 Número Aleatorio: 0.5612689535045131 Epsilon: 0.8973999999999993\n",
      "Step: 27 Política Aleatoria - Accion 0\n",
      "Step: 28 Número Aleatorio: 0.7248794504141232 Epsilon: 0.8935999999999993\n",
      "Step: 28 Política Aleatoria - Accion 0\n",
      "Step: 29 Número Aleatorio: 0.8767217750863191 Epsilon: 0.8897999999999993\n",
      "Step: 29 Política Aleatoria - Accion 2\n",
      "Step: 30 Número Aleatorio: 0.5865273709569038 Epsilon: 0.8859999999999992\n",
      "Step: 30 Política Aleatoria - Accion 2\n",
      "Step: 31 Número Aleatorio: 0.7580822100197314 Epsilon: 0.8821999999999992\n",
      "Step: 31 Política Aleatoria - Accion 1\n",
      "Step: 32 Número Aleatorio: 0.9973025291842349 Epsilon: 0.8783999999999992\n",
      "Step: 32 x: -0.56381917  v: -0.00052519585\n",
      "Step: 32 Política Determinista - Accion 0\n",
      "Step: 33 Número Aleatorio: 0.06196829574971319 Epsilon: 0.8745999999999992\n",
      "Step: 33 Política Aleatoria - Accion 0\n",
      "Step: 34 Número Aleatorio: 0.4898061799216886 Epsilon: 0.8707999999999991\n",
      "Step: 34 Política Aleatoria - Accion 1\n",
      "Step: 35 Número Aleatorio: 0.06947832986390134 Epsilon: 0.8669999999999991\n",
      "Step: 35 Política Aleatoria - Accion 0\n",
      "Step: 36 Número Aleatorio: 0.5677288183259951 Epsilon: 0.8631999999999991\n",
      "Step: 36 Política Aleatoria - Accion 1\n",
      "Step: 37 Número Aleatorio: 0.2740974194090856 Epsilon: 0.859399999999999\n",
      "Step: 37 Política Aleatoria - Accion 1\n",
      "Step: 38 Número Aleatorio: 0.804683095712027 Epsilon: 0.855599999999999\n",
      "Step: 38 Política Aleatoria - Accion 0\n",
      "Step: 39 Número Aleatorio: 0.16047766909195516 Epsilon: 0.851799999999999\n",
      "Step: 39 Política Aleatoria - Accion 2\n",
      "Step: 40 Número Aleatorio: 0.9363698670482677 Epsilon: 0.847999999999999\n",
      "Step: 40 x: -0.57715386  v: -0.0007614591\n",
      "Step: 40 Política Determinista - Accion 0\n",
      "Step: 41 Número Aleatorio: 0.7120372491519288 Epsilon: 0.844199999999999\n",
      "Step: 41 Política Aleatoria - Accion 0\n",
      "Step: 42 Número Aleatorio: 0.05944282506597354 Epsilon: 0.8403999999999989\n",
      "Step: 42 Política Aleatoria - Accion 1\n",
      "Step: 43 Número Aleatorio: 0.5193218139794191 Epsilon: 0.8365999999999989\n",
      "Step: 43 Política Aleatoria - Accion 1\n",
      "Step: 44 Número Aleatorio: 0.028289823838845263 Epsilon: 0.8327999999999989\n",
      "Step: 44 Política Aleatoria - Accion 0\n",
      "Step: 45 Número Aleatorio: 0.6863393760250289 Epsilon: 0.8289999999999988\n",
      "Step: 45 Política Aleatoria - Accion 0\n",
      "Step: 46 Número Aleatorio: 0.5515671537997381 Epsilon: 0.8251999999999988\n",
      "Step: 46 Política Aleatoria - Accion 2\n",
      "Step: 47 Número Aleatorio: 0.38958032729069625 Epsilon: 0.8213999999999988\n",
      "Step: 47 Política Aleatoria - Accion 2\n",
      "Step: 48 Número Aleatorio: 0.23625667702544395 Epsilon: 0.8175999999999988\n",
      "Step: 48 Política Aleatoria - Accion 0\n",
      "Step: 49 Número Aleatorio: 0.9706828516694841 Epsilon: 0.8137999999999987\n",
      "Step: 49 x: -0.5866564  v: 0.00022967458\n",
      "Step: 49 Política Determinista - Accion 2\n",
      "Step: 50 Número Aleatorio: 0.10442162468973726 Epsilon: 0.8099999999999987\n",
      "Step: 50 Política Aleatoria - Accion 2\n",
      "Step: 51 Número Aleatorio: 0.9617213094717146 Epsilon: 0.8061999999999987\n",
      "Step: 51 x: -0.58179927  v: 0.0031573807\n",
      "Step: 51 Política Determinista - Accion 2\n",
      "Step: 52 Número Aleatorio: 0.22595840482930363 Epsilon: 0.8023999999999987\n",
      "Step: 52 Política Aleatoria - Accion 2\n",
      "Step: 53 Número Aleatorio: 0.32044198965278736 Epsilon: 0.7985999999999986\n",
      "Step: 53 Política Aleatoria - Accion 1\n",
      "Step: 54 Número Aleatorio: 0.9686568564329541 Epsilon: 0.7947999999999986\n",
      "Step: 54 x: -0.5648677  v: 0.006347917\n",
      "Step: 54 Política Determinista - Accion 2\n",
      "Step: 55 Número Aleatorio: 0.961112841179447 Epsilon: 0.7909999999999986\n",
      "Step: 55 x: -0.557211  v: 0.0076566436\n",
      "Step: 55 Política Determinista - Accion 2\n",
      "Step: 56 Número Aleatorio: 0.7563045734433811 Epsilon: 0.7871999999999986\n",
      "Step: 56 Política Aleatoria - Accion 0\n",
      "Step: 57 Número Aleatorio: 0.22210396595666537 Epsilon: 0.7833999999999985\n",
      "Step: 57 Política Aleatoria - Accion 1\n",
      "Step: 58 Número Aleatorio: 0.47876345110488716 Epsilon: 0.7795999999999985\n",
      "Step: 58 Política Aleatoria - Accion 0\n",
      "Step: 59 Número Aleatorio: 0.12819437452009408 Epsilon: 0.7757999999999985\n",
      "Step: 59 Política Aleatoria - Accion 2\n",
      "Step: 60 Número Aleatorio: 0.10969669820433248 Epsilon: 0.7719999999999985\n",
      "Step: 60 Política Aleatoria - Accion 1\n",
      "Step: 61 Número Aleatorio: 0.6073913185655448 Epsilon: 0.7681999999999984\n",
      "Step: 61 Política Aleatoria - Accion 1\n",
      "Step: 62 Número Aleatorio: 0.8514161264360924 Epsilon: 0.7643999999999984\n",
      "Step: 62 x: -0.500066  v: 0.008119837\n",
      "Step: 62 Política Determinista - Accion 2\n",
      "Step: 63 Número Aleatorio: 0.8848459383635707 Epsilon: 0.7605999999999984\n",
      "Step: 63 x: -0.4911225  v: 0.008943488\n",
      "Step: 63 Política Determinista - Accion 2\n",
      "Step: 64 Número Aleatorio: 0.12303952047212285 Epsilon: 0.7567999999999984\n",
      "Step: 64 Política Aleatoria - Accion 0\n",
      "Step: 65 Número Aleatorio: 0.03974324932731632 Epsilon: 0.7529999999999983\n",
      "Step: 65 Política Aleatoria - Accion 1\n",
      "Step: 66 Número Aleatorio: 0.2957079118512682 Epsilon: 0.7491999999999983\n",
      "Step: 66 Política Aleatoria - Accion 0\n",
      "Step: 67 Número Aleatorio: 0.5757857509709529 Epsilon: 0.7453999999999983\n",
      "Step: 67 Política Aleatoria - Accion 1\n",
      "Step: 68 Número Aleatorio: 0.18422872913422172 Epsilon: 0.7415999999999983\n",
      "Step: 68 Política Aleatoria - Accion 2\n",
      "Step: 69 Número Aleatorio: 0.6862480179136308 Epsilon: 0.7377999999999982\n",
      "Step: 69 Política Aleatoria - Accion 2\n",
      "Step: 70 Número Aleatorio: 0.6029819231724074 Epsilon: 0.7339999999999982\n",
      "Step: 70 Política Aleatoria - Accion 0\n",
      "Step: 71 Número Aleatorio: 0.3984384209039865 Epsilon: 0.7301999999999982\n",
      "Step: 71 Política Aleatoria - Accion 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 72 Número Aleatorio: 0.15331658623267785 Epsilon: 0.7263999999999982\n",
      "Step: 72 Política Aleatoria - Accion 0\n",
      "Step: 73 Número Aleatorio: 0.29088843617679994 Epsilon: 0.7225999999999981\n",
      "Step: 73 Política Aleatoria - Accion 0\n",
      "Step: 74 Número Aleatorio: 0.45697928516577835 Epsilon: 0.7187999999999981\n",
      "Step: 74 Política Aleatoria - Accion 0\n",
      "Step: 75 Número Aleatorio: 0.2065209037444391 Epsilon: 0.7149999999999981\n",
      "Step: 75 Política Aleatoria - Accion 2\n",
      "Step: 76 Número Aleatorio: 0.5970816743389906 Epsilon: 0.7111999999999981\n",
      "Step: 76 Política Aleatoria - Accion 0\n",
      "Step: 77 Número Aleatorio: 0.11749152833432652 Epsilon: 0.707399999999998\n",
      "Step: 77 Política Aleatoria - Accion 2\n",
      "Step: 78 Número Aleatorio: 0.6827873756040193 Epsilon: 0.703599999999998\n",
      "Step: 78 Política Aleatoria - Accion 0\n",
      "Step: 79 Número Aleatorio: 0.8062556869153275 Epsilon: 0.699799999999998\n",
      "Step: 79 x: -0.43218222  v: -0.0033451482\n",
      "Step: 79 Política Determinista - Accion 0\n",
      "Step: 80 Número Aleatorio: 0.3445610166162004 Epsilon: 0.695999999999998\n",
      "Step: 80 Política Aleatoria - Accion 0\n",
      "Step: 81 Número Aleatorio: 0.03194128312755762 Epsilon: 0.6921999999999979\n",
      "Step: 81 Política Aleatoria - Accion 2\n",
      "Step: 82 Número Aleatorio: 0.8890982043195768 Epsilon: 0.6883999999999979\n",
      "Step: 82 x: -0.4501226  v: -0.006255237\n",
      "Step: 82 Política Determinista - Accion 0\n",
      "Step: 83 Número Aleatorio: 0.26059486277814314 Epsilon: 0.6845999999999979\n",
      "Step: 83 Política Aleatoria - Accion 2\n",
      "Step: 84 Número Aleatorio: 0.9203858564236358 Epsilon: 0.6807999999999979\n",
      "Step: 84 x: -0.4652157  v: -0.007291233\n",
      "Step: 84 Política Determinista - Accion 0\n",
      "Step: 85 Número Aleatorio: 0.19871157994871247 Epsilon: 0.6769999999999978\n",
      "Step: 85 Política Aleatoria - Accion 0\n",
      "Step: 86 Número Aleatorio: 0.680017696542385 Epsilon: 0.6731999999999978\n",
      "Step: 86 x: -0.4840405  v: -0.010097916\n",
      "Step: 86 Política Determinista - Accion 0\n",
      "Step: 87 Número Aleatorio: 0.6398763035504308 Epsilon: 0.6693999999999978\n",
      "Step: 87 Política Aleatoria - Accion 1\n",
      "Step: 88 Número Aleatorio: 0.6568560673272871 Epsilon: 0.6655999999999977\n",
      "Step: 88 Política Aleatoria - Accion 0\n",
      "Step: 89 Número Aleatorio: 0.003484581869391601 Epsilon: 0.6617999999999977\n",
      "Step: 89 Política Aleatoria - Accion 2\n",
      "Step: 90 Número Aleatorio: 0.672627731381971 Epsilon: 0.6579999999999977\n",
      "Step: 90 x: -0.5315261  v: -0.011757762\n",
      "Step: 90 Política Determinista - Accion 0\n",
      "Step: 91 Número Aleatorio: 0.34717161015911835 Epsilon: 0.6541999999999977\n",
      "Step: 91 Política Aleatoria - Accion 2\n",
      "Step: 92 Número Aleatorio: 0.5172154478335923 Epsilon: 0.6503999999999976\n",
      "Step: 92 Política Aleatoria - Accion 0\n",
      "Step: 93 Número Aleatorio: 0.4636953480186947 Epsilon: 0.6465999999999976\n",
      "Step: 93 Política Aleatoria - Accion 0\n",
      "Step: 94 Número Aleatorio: 0.8126239811731487 Epsilon: 0.6427999999999976\n",
      "Step: 94 x: -0.5810412  v: -0.0129702715\n",
      "Step: 94 Política Determinista - Accion 0\n",
      "Step: 95 Número Aleatorio: 0.8751478452675496 Epsilon: 0.6389999999999976\n",
      "Step: 95 x: -0.5945828  v: -0.013541582\n",
      "Step: 95 Política Determinista - Accion 0\n",
      "Step: 96 Número Aleatorio: 0.17183595600544266 Epsilon: 0.6351999999999975\n",
      "Step: 96 Política Aleatoria - Accion 1\n",
      "Step: 97 Número Aleatorio: 0.42810283855736886 Epsilon: 0.6313999999999975\n",
      "Step: 97 Política Aleatoria - Accion 1\n",
      "Step: 98 Número Aleatorio: 0.6569042400199853 Epsilon: 0.6275999999999975\n",
      "Step: 98 x: -0.6346341  v: -0.01265544\n",
      "Step: 98 Política Determinista - Accion 0\n",
      "Step: 99 Número Aleatorio: 0.7106994944020708 Epsilon: 0.6237999999999975\n",
      "Step: 99 x: -0.6474721  v: -0.01283799\n",
      "Step: 99 Política Determinista - Accion 0\n",
      "Step: 100 Número Aleatorio: 0.20306790525451834 Epsilon: 0.6199999999999974\n",
      "Step: 100 Política Aleatoria - Accion 1\n",
      "Step: 101 Número Aleatorio: 0.36824595031204665 Epsilon: 0.6161999999999974\n",
      "Step: 101 Política Aleatoria - Accion 1\n",
      "Step: 102 Número Aleatorio: 0.7779982488330454 Epsilon: 0.6123999999999974\n",
      "Step: 102 x: -0.6831888  v: -0.010853843\n",
      "Step: 102 Política Determinista - Accion 0\n",
      "Step: 103 Número Aleatorio: 0.948543669317356 Epsilon: 0.6085999999999974\n",
      "Step: 103 x: -0.6938909  v: -0.010702123\n",
      "Step: 103 Política Determinista - Accion 0\n",
      "Step: 104 Número Aleatorio: 0.7421873643851371 Epsilon: 0.6047999999999973\n",
      "Step: 104 x: -0.7043707  v: -0.010479768\n",
      "Step: 104 Política Determinista - Accion 0\n",
      "Step: 105 Número Aleatorio: 0.09459172729486154 Epsilon: 0.6009999999999973\n",
      "Step: 105 Política Aleatoria - Accion 1\n",
      "Step: 106 Número Aleatorio: 0.04636584553883916 Epsilon: 0.5971999999999973\n",
      "Step: 106 Política Aleatoria - Accion 1\n",
      "Step: 107 Número Aleatorio: 0.20422783732224759 Epsilon: 0.5933999999999973\n",
      "Step: 107 Política Aleatoria - Accion 1\n",
      "Step: 108 Número Aleatorio: 0.15076536255246997 Epsilon: 0.5895999999999972\n",
      "Step: 108 Política Aleatoria - Accion 1\n",
      "Step: 109 Número Aleatorio: 0.34180635423120753 Epsilon: 0.5857999999999972\n",
      "Step: 109 Política Aleatoria - Accion 2\n",
      "Step: 110 Número Aleatorio: 0.9911710792744386 Epsilon: 0.5819999999999972\n",
      "Step: 110 x: -0.7432194  v: -0.0019569942\n",
      "Step: 110 Política Determinista - Accion 0\n",
      "Step: 111 Número Aleatorio: 0.1374873534408707 Epsilon: 0.5781999999999972\n",
      "Step: 111 Política Aleatoria - Accion 0\n",
      "Step: 112 Número Aleatorio: 0.49124105809564234 Epsilon: 0.5743999999999971\n",
      "Step: 112 Política Aleatoria - Accion 1\n",
      "Step: 113 Número Aleatorio: 0.3231636099159291 Epsilon: 0.5705999999999971\n",
      "Step: 113 Política Aleatoria - Accion 1\n",
      "Step: 114 Número Aleatorio: 0.8281906826016393 Epsilon: 0.5667999999999971\n",
      "Step: 114 x: -0.7426794  v: 0.0021971168\n",
      "Step: 114 Política Determinista - Accion 2\n",
      "Step: 115 Número Aleatorio: 0.8772632920442061 Epsilon: 0.5629999999999971\n",
      "Step: 115 x: -0.737955  v: 0.004724456\n",
      "Step: 115 Política Determinista - Accion 2\n",
      "Step: 116 Número Aleatorio: 0.8409985128525221 Epsilon: 0.559199999999997\n",
      "Step: 116 x: -0.73073137  v: 0.0072235907\n",
      "Step: 116 Política Determinista - Accion 2\n",
      "Step: 117 Número Aleatorio: 0.259538353762376 Epsilon: 0.555399999999997\n",
      "Step: 117 Política Aleatoria - Accion 1\n",
      "Step: 118 Número Aleatorio: 0.9503695067483058 Epsilon: 0.551599999999997\n",
      "Step: 118 x: -0.7099775  v: 0.011074823\n",
      "Step: 118 Política Determinista - Accion 2\n",
      "Step: 119 Número Aleatorio: 0.08041628021291547 Epsilon: 0.547799999999997\n",
      "Step: 119 Política Aleatoria - Accion 0\n",
      "Step: 120 Número Aleatorio: 0.36839908133723676 Epsilon: 0.5439999999999969\n",
      "Step: 120 Política Aleatoria - Accion 2\n",
      "Step: 121 Número Aleatorio: 0.767510489365216 Epsilon: 0.5401999999999969\n",
      "Step: 121 x: -0.66714483  v: 0.01579088\n",
      "Step: 121 Política Determinista - Accion 2\n",
      "Step: 122 Número Aleatorio: 0.38553274786399516 Epsilon: 0.5363999999999969\n",
      "Step: 122 Política Aleatoria - Accion 0\n",
      "Step: 123 Número Aleatorio: 0.40752615728629116 Epsilon: 0.5325999999999969\n",
      "Step: 123 Política Aleatoria - Accion 0\n",
      "Step: 124 Número Aleatorio: 0.8267824027238108 Epsilon: 0.5287999999999968\n",
      "Step: 124 x: -0.61400443  v: 0.017550744\n",
      "Step: 124 Política Determinista - Accion 2\n",
      "Step: 125 Número Aleatorio: 0.4209527905255096 Epsilon: 0.5249999999999968\n",
      "Step: 125 Política Aleatoria - Accion 2\n",
      "Step: 126 Número Aleatorio: 0.8622061943104882 Epsilon: 0.5211999999999968\n",
      "Step: 126 x: -0.57403356  v: 0.020750344\n",
      "Step: 126 Política Determinista - Accion 2\n",
      "Step: 127 Número Aleatorio: 0.6419688946457158 Epsilon: 0.5173999999999968\n",
      "Step: 127 x: -0.5519064  v: 0.022127163\n",
      "Step: 127 Política Determinista - Accion 2\n",
      "Step: 128 Número Aleatorio: 0.6707831122356795 Epsilon: 0.5135999999999967\n",
      "Step: 128 x: -0.5285672  v: 0.023339216\n",
      "Step: 128 Política Determinista - Accion 2\n",
      "Step: 129 Número Aleatorio: 0.23132260619108902 Epsilon: 0.5097999999999967\n",
      "Step: 129 Política Aleatoria - Accion 2\n",
      "Step: 130 Número Aleatorio: 0.4336831795211542 Epsilon: 0.5059999999999967\n",
      "Step: 130 Política Aleatoria - Accion 2\n",
      "Step: 131 Número Aleatorio: 0.2965032594723873 Epsilon: 0.5021999999999966\n",
      "Step: 131 Política Aleatoria - Accion 2\n",
      "Step: 132 Número Aleatorio: 0.5119827490913844 Epsilon: 0.4983999999999966\n",
      "Step: 132 x: -0.4266904  v: 0.026372124\n",
      "Step: 132 Política Determinista - Accion 2\n",
      "Step: 133 Número Aleatorio: 0.4753929683118714 Epsilon: 0.4945999999999966\n",
      "Step: 133 Política Aleatoria - Accion 0\n",
      "Step: 134 Número Aleatorio: 0.680954929254377 Epsilon: 0.4907999999999966\n",
      "Step: 134 x: -0.37528503  v: 0.024749855\n",
      "Step: 134 Política Determinista - Accion 2\n",
      "Step: 135 Número Aleatorio: 0.3346775795158816 Epsilon: 0.48699999999999655\n",
      "Step: 135 Política Aleatoria - Accion 1\n",
      "Step: 136 Número Aleatorio: 0.7816241459623836 Epsilon: 0.4831999999999965\n",
      "Step: 136 x: -0.3271773  v: 0.023433894\n",
      "Step: 136 Política Determinista - Accion 2\n",
      "Step: 137 Número Aleatorio: 0.2567692520901921 Epsilon: 0.4793999999999965\n",
      "Step: 137 Política Aleatoria - Accion 2\n",
      "Step: 138 Número Aleatorio: 0.42626365009019584 Epsilon: 0.47559999999999647\n",
      "Step: 138 Política Aleatoria - Accion 0\n",
      "Step: 139 Número Aleatorio: 0.2711523736008644 Epsilon: 0.47179999999999644\n",
      "Step: 139 Política Aleatoria - Accion 2\n",
      "Step: 140 Número Aleatorio: 0.5522034493625452 Epsilon: 0.4679999999999964\n",
      "Step: 140 x: -0.24267526  v: 0.01908733\n",
      "Step: 140 Política Determinista - Accion 2\n",
      "Step: 141 Número Aleatorio: 0.9775163397841808 Epsilon: 0.4641999999999964\n",
      "Step: 141 x: -0.22445416  v: 0.018221106\n",
      "Step: 141 Política Determinista - Accion 2\n",
      "Step: 142 Número Aleatorio: 0.7310903871702752 Epsilon: 0.46039999999999637\n",
      "Step: 142 x: -0.20718738  v: 0.017266782\n",
      "Step: 142 Política Determinista - Accion 2\n",
      "Step: 143 Número Aleatorio: 0.3341451674583098 Epsilon: 0.45659999999999634\n",
      "Step: 143 Política Aleatoria - Accion 1\n",
      "Step: 144 Número Aleatorio: 0.46272047487304635 Epsilon: 0.4527999999999963\n",
      "Step: 144 x: -0.17681955  v: 0.014133472\n",
      "Step: 144 Política Determinista - Accion 2\n",
      "Step: 145 Número Aleatorio: 0.6788312009698547 Epsilon: 0.4489999999999963\n",
      "Step: 145 x: -0.16384251  v: 0.012977034\n",
      "Step: 145 Política Determinista - Accion 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 146 Número Aleatorio: 0.4173604193995897 Epsilon: 0.44519999999999627\n",
      "Step: 146 Política Aleatoria - Accion 1\n",
      "Step: 147 Número Aleatorio: 0.08943963438977942 Epsilon: 0.44139999999999624\n",
      "Step: 147 Política Aleatoria - Accion 0\n",
      "Step: 148 Número Aleatorio: 0.8951868070365449 Epsilon: 0.4375999999999962\n",
      "Step: 148 x: -0.13628705  v: 0.0062537924\n",
      "Step: 148 Política Determinista - Accion 2\n",
      "Step: 149 Número Aleatorio: 0.6434211004351358 Epsilon: 0.4337999999999962\n",
      "Step: 149 x: -0.13132718  v: 0.004959857\n",
      "Step: 149 Política Determinista - Accion 2\n",
      "Step: 150 Número Aleatorio: 0.30840359795427197 Epsilon: 0.42999999999999616\n",
      "Step: 150 Política Aleatoria - Accion 2\n",
      "Step: 151 Número Aleatorio: 0.6697706916463616 Epsilon: 0.42619999999999614\n",
      "Step: 151 x: -0.12534325  v: 0.0023325435\n",
      "Step: 151 Política Determinista - Accion 2\n",
      "Step: 152 Número Aleatorio: 0.37156918735031885 Epsilon: 0.4223999999999961\n",
      "Step: 152 Política Aleatoria - Accion 1\n",
      "Step: 153 Número Aleatorio: 0.3592737938964403 Epsilon: 0.4185999999999961\n",
      "Step: 153 Política Aleatoria - Accion 1\n",
      "Step: 154 Número Aleatorio: 0.3777200442180416 Epsilon: 0.41479999999999606\n",
      "Step: 154 Política Aleatoria - Accion 0\n",
      "Step: 155 Número Aleatorio: 0.24151985521233754 Epsilon: 0.41099999999999604\n",
      "Step: 155 Política Aleatoria - Accion 2\n",
      "Step: 156 Número Aleatorio: 0.5805933785525415 Epsilon: 0.407199999999996\n",
      "Step: 156 x: -0.14451542  v: -0.008253598\n",
      "Step: 156 Política Determinista - Accion 0\n",
      "Step: 157 Número Aleatorio: 0.5598148772568374 Epsilon: 0.403399999999996\n",
      "Step: 157 x: -0.15603772  v: -0.0115223015\n",
      "Step: 157 Política Determinista - Accion 0\n",
      "Step: 158 Número Aleatorio: 0.4145121448476927 Epsilon: 0.39959999999999596\n",
      "Step: 158 x: -0.17079107  v: -0.014753355\n",
      "Step: 158 Política Determinista - Accion 0\n",
      "Step: 159 Número Aleatorio: 0.5023227676467472 Epsilon: 0.39579999999999593\n",
      "Step: 159 x: -0.18872339  v: -0.017932314\n",
      "Step: 159 Política Determinista - Accion 0\n",
      "Step: 160 Número Aleatorio: 0.5922676750585548 Epsilon: 0.3919999999999959\n",
      "Step: 160 x: -0.20976561  v: -0.021042217\n",
      "Step: 160 Política Determinista - Accion 0\n",
      "Step: 161 Número Aleatorio: 0.7281467825355081 Epsilon: 0.3881999999999959\n",
      "Step: 161 x: -0.23382893  v: -0.02406332\n",
      "Step: 161 Política Determinista - Accion 0\n",
      "Step: 162 Número Aleatorio: 0.24923639642578554 Epsilon: 0.38439999999999586\n",
      "Step: 162 Política Aleatoria - Accion 0\n",
      "Step: 163 Número Aleatorio: 0.6979702859918081 Epsilon: 0.38059999999999583\n",
      "Step: 163 x: -0.29054803  v: -0.02974608\n",
      "Step: 163 Política Determinista - Accion 0\n",
      "Step: 164 Número Aleatorio: 0.00813948538419984 Epsilon: 0.3767999999999958\n",
      "Step: 164 Política Aleatoria - Accion 2\n",
      "Step: 165 Número Aleatorio: 0.769772579645964 Epsilon: 0.3729999999999958\n",
      "Step: 165 x: -0.35567394  v: -0.032770913\n",
      "Step: 165 Política Determinista - Accion 0\n",
      "Step: 166 Número Aleatorio: 0.4324254416684723 Epsilon: 0.36919999999999575\n",
      "Step: 166 x: -0.3906517  v: -0.03497775\n",
      "Step: 166 Política Determinista - Accion 0\n",
      "Step: 167 Número Aleatorio: 0.2792463710557065 Epsilon: 0.36539999999999573\n",
      "Step: 167 Política Aleatoria - Accion 2\n",
      "Step: 168 Número Aleatorio: 0.3556242996464627 Epsilon: 0.3615999999999957\n",
      "Step: 168 Política Aleatoria - Accion 1\n",
      "Step: 169 Número Aleatorio: 0.4352745290302703 Epsilon: 0.3577999999999957\n",
      "Step: 169 x: -0.5013604  v: -0.037101403\n",
      "Step: 169 Política Determinista - Accion 0\n",
      "Step: 170 Número Aleatorio: 0.7334633816320628 Epsilon: 0.35399999999999565\n",
      "Step: 170 x: -0.5396285  v: -0.038268067\n",
      "Step: 170 Política Determinista - Accion 0\n",
      "Step: 171 Número Aleatorio: 0.5354391531874801 Epsilon: 0.3501999999999956\n",
      "Step: 171 x: -0.57877636  v: -0.03914789\n",
      "Step: 171 Política Determinista - Accion 0\n",
      "Step: 172 Número Aleatorio: 0.34930506377493853 Epsilon: 0.3463999999999956\n",
      "Step: 172 x: -0.61851233  v: -0.039735947\n",
      "Step: 172 Política Determinista - Accion 0\n",
      "Step: 173 Número Aleatorio: 0.613263890272655 Epsilon: 0.3425999999999956\n",
      "Step: 173 x: -0.65854603  v: -0.040033672\n",
      "Step: 173 Política Determinista - Accion 0\n",
      "Step: 174 Número Aleatorio: 0.3722950416983587 Epsilon: 0.33879999999999555\n",
      "Step: 174 x: -0.698595  v: -0.04004899\n",
      "Step: 174 Política Determinista - Accion 0\n",
      "Step: 175 Número Aleatorio: 0.7059121937208579 Epsilon: 0.3349999999999955\n",
      "Step: 175 x: -0.738391  v: -0.039795984\n",
      "Step: 175 Política Determinista - Accion 0\n",
      "Step: 176 Número Aleatorio: 0.7426037539233856 Epsilon: 0.3311999999999955\n",
      "Step: 176 x: -0.7776852  v: -0.03929423\n",
      "Step: 176 Política Determinista - Accion 0\n",
      "Step: 177 Número Aleatorio: 0.16797037852008923 Epsilon: 0.3273999999999955\n",
      "Step: 177 Política Aleatoria - Accion 0\n",
      "Step: 178 Número Aleatorio: 0.7165695265920787 Epsilon: 0.32359999999999545\n",
      "Step: 178 x: -0.8538973  v: -0.03764424\n",
      "Step: 178 Política Determinista - Accion 0\n",
      "Step: 179 Número Aleatorio: 0.821707831339972 Epsilon: 0.3197999999999954\n",
      "Step: 179 x: -0.89045024  v: -0.036552947\n",
      "Step: 179 Política Determinista - Accion 0\n",
      "Step: 180 Número Aleatorio: 0.8071459957217793 Epsilon: 0.3159999999999954\n",
      "Step: 180 x: -0.9257745  v: -0.0353243\n",
      "Step: 180 Política Determinista - Accion 0\n",
      "Step: 181 Número Aleatorio: 0.6417188082548811 Epsilon: 0.31219999999999537\n",
      "Step: 181 x: -0.9597629  v: -0.03398834\n",
      "Step: 181 Política Determinista - Accion 0\n",
      "Step: 182 Número Aleatorio: 0.24021494486421335 Epsilon: 0.30839999999999534\n",
      "Step: 182 Política Aleatoria - Accion 1\n",
      "Step: 183 Número Aleatorio: 0.8436911002001366 Epsilon: 0.3045999999999953\n",
      "Step: 183 x: -1.0224444  v: -0.030107636\n",
      "Step: 183 Política Determinista - Accion 0\n",
      "Step: 184 Número Aleatorio: 0.5869462071750466 Epsilon: 0.3007999999999953\n",
      "Step: 184 x: -1.0510589  v: -0.028614525\n",
      "Step: 184 Política Determinista - Accion 0\n",
      "Step: 185 Número Aleatorio: 0.918512720524246 Epsilon: 0.29699999999999527\n",
      "Step: 185 x: -1.0781736  v: -0.027114693\n",
      "Step: 185 Política Determinista - Accion 0\n",
      "Step: 186 Número Aleatorio: 0.808648108316504 Epsilon: 0.29319999999999524\n",
      "Step: 186 x: -1.1037991  v: -0.02562548\n",
      "Step: 186 Política Determinista - Accion 0\n",
      "Step: 187 Número Aleatorio: 0.009608134642898558 Epsilon: 0.2893999999999952\n",
      "Step: 187 Política Aleatoria - Accion 1\n",
      "Step: 188 Número Aleatorio: 0.6403082827979527 Epsilon: 0.2855999999999952\n",
      "Step: 188 x: -1.1496949  v: -0.021734457\n",
      "Step: 188 Política Determinista - Accion 0\n",
      "Step: 189 Número Aleatorio: 0.29309682241748325 Epsilon: 0.28179999999999517\n",
      "Step: 189 x: -1.1700467  v: -0.020351717\n",
      "Step: 189 Política Determinista - Accion 0\n",
      "Step: 190 Número Aleatorio: 0.5075058858692835 Epsilon: 0.27799999999999514\n",
      "Step: 190 x: -1.1890663  v: -0.019019589\n",
      "Step: 190 Política Determinista - Accion 0\n",
      "Step: 191 Número Aleatorio: 0.1742269608958077 Epsilon: 0.2741999999999951\n",
      "Step: 191 Política Aleatoria - Accion 1\n",
      "Step: 192 Número Aleatorio: 0.4651911046232018 Epsilon: 0.2703999999999951\n",
      "Step: 192 x: -1.1977581  v: 0.002241896\n",
      "Step: 192 Política Determinista - Accion 2\n",
      "Step: 193 Número Aleatorio: 0.35513861460292717 Epsilon: 0.26659999999999506\n",
      "Step: 193 x: -1.192267  v: 0.0054911817\n",
      "Step: 193 Política Determinista - Accion 2\n",
      "Step: 194 Número Aleatorio: 0.8504375885098471 Epsilon: 0.26279999999999504\n",
      "Step: 194 x: -1.1835088  v: 0.008758138\n",
      "Step: 194 Política Determinista - Accion 2\n",
      "Step: 195 Número Aleatorio: 0.13650876556777403 Epsilon: 0.258999999999995\n",
      "Step: 195 Política Aleatoria - Accion 1\n",
      "Step: 196 Número Aleatorio: 0.6690404841140508 Epsilon: 0.255199999999995\n",
      "Step: 196 x: -1.1570765  v: 0.0143802995\n",
      "Step: 196 Política Determinista - Accion 2\n",
      "Step: 197 Número Aleatorio: 0.06326260503906211 Epsilon: 0.25139999999999496\n",
      "Step: 197 Política Aleatoria - Accion 1\n",
      "Step: 198 Número Aleatorio: 0.9887702019091408 Epsilon: 0.24759999999999496\n",
      "Step: 198 x: -1.11918  v: 0.02015081\n",
      "Step: 198 Política Determinista - Accion 2\n",
      "Step: 199 Número Aleatorio: 0.506035929307479 Epsilon: 0.24379999999999497\n",
      "Step: 199 x: -1.0955873  v: 0.023592744\n",
      "Step: 199 Política Determinista - Accion 2\n",
      "Step: 200 Número Aleatorio: 0.8266696322467623 Epsilon: 0.23999999999999497\n",
      "Step: 200 x: -1.0685208  v: 0.027066449\n",
      "Step: 200 Política Determinista - Accion 2\n",
      "Step: 201 Número Aleatorio: 0.06487091668143752 Epsilon: 0.23619999999999497\n",
      "Step: 201 Política Aleatoria - Accion 2\n",
      "Step: 202 Número Aleatorio: 0.9694215761158652 Epsilon: 0.23239999999999497\n",
      "Step: 202 x: -1.0038991  v: 0.034060374\n",
      "Step: 202 Política Determinista - Accion 2\n",
      "Step: 203 Número Aleatorio: 0.41436806470613563 Epsilon: 0.22859999999999497\n",
      "Step: 203 x: -0.96635973  v: 0.037539314\n",
      "Step: 203 Política Determinista - Accion 2\n",
      "Step: 204 Número Aleatorio: 0.14518912238939885 Epsilon: 0.22479999999999498\n",
      "Step: 204 Política Aleatoria - Accion 0\n",
      "Step: 205 Número Aleatorio: 0.8435437816696902 Epsilon: 0.22099999999999498\n",
      "Step: 205 x: -0.8830925  v: 0.0423011\n",
      "Step: 205 Política Determinista - Accion 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 206 Número Aleatorio: 0.9680674298024724 Epsilon: 0.21719999999999498\n",
      "Step: 206 x: -0.8375883  v: 0.0455042\n",
      "Step: 206 Política Determinista - Accion 2\n",
      "Step: 207 Número Aleatorio: 0.2764035979954491 Epsilon: 0.21339999999999498\n",
      "Step: 207 x: -0.7890623  v: 0.048525997\n",
      "Step: 207 Política Determinista - Accion 2\n",
      "Step: 208 Número Aleatorio: 0.06323913703496775 Epsilon: 0.20959999999999498\n",
      "Step: 208 Política Aleatoria - Accion 0\n",
      "Step: 209 Número Aleatorio: 0.49183513961345837 Epsilon: 0.205799999999995\n",
      "Step: 209 x: -0.68593824  v: 0.051810987\n",
      "Step: 209 Política Determinista - Accion 2\n",
      "Step: 210 Número Aleatorio: 0.9502401894049981 Epsilon: 0.201999999999995\n",
      "Step: 210 x: -0.6319573  v: 0.05398097\n",
      "Step: 210 Política Determinista - Accion 2\n",
      "Step: 211 Número Aleatorio: 0.03620881854475011 Epsilon: 0.198199999999995\n",
      "Step: 211 Política Aleatoria - Accion 1\n",
      "Step: 212 Número Aleatorio: 0.17861721759817173 Epsilon: 0.194399999999995\n",
      "Step: 212 Política Aleatoria - Accion 1\n",
      "Step: 213 Número Aleatorio: 0.7962818434826208 Epsilon: 0.190599999999995\n",
      "Step: 213 x: -0.46386054  v: 0.056145184\n",
      "Step: 213 Política Determinista - Accion 2\n",
      "Step: 214 Número Aleatorio: 0.46275497245560115 Epsilon: 0.186799999999995\n",
      "Step: 214 x: -0.407161  v: 0.05669954\n",
      "Step: 214 Política Determinista - Accion 2\n",
      "Step: 215 Número Aleatorio: 0.5365730683736429 Epsilon: 0.182999999999995\n",
      "Step: 215 x: -0.3503171  v: 0.056843907\n",
      "Step: 215 Política Determinista - Accion 2\n",
      "Step: 216 Número Aleatorio: 0.6673323562747756 Epsilon: 0.179199999999995\n",
      "Step: 216 x: -0.29371503  v: 0.056602042\n",
      "Step: 216 Política Determinista - Accion 2\n",
      "Step: 217 Número Aleatorio: 0.5872994118696727 Epsilon: 0.175399999999995\n",
      "Step: 217 x: -0.23770367  v: 0.056011375\n",
      "Step: 217 Política Determinista - Accion 2\n",
      "Step: 218 Número Aleatorio: 0.0069015754982875155 Epsilon: 0.171599999999995\n",
      "Step: 218 Política Aleatoria - Accion 0\n",
      "Step: 219 Número Aleatorio: 0.2494486538206805 Epsilon: 0.167799999999995\n",
      "Step: 219 x: -0.13059682  v: 0.0519863\n",
      "Step: 219 Política Determinista - Accion 2\n",
      "Step: 220 Número Aleatorio: 0.4768946793659986 Epsilon: 0.163999999999995\n",
      "Step: 220 x: -0.07992109  v: 0.050675735\n",
      "Step: 220 Política Determinista - Accion 2\n",
      "Step: 221 Número Aleatorio: 0.32852983608335384 Epsilon: 0.160199999999995\n",
      "Step: 221 x: -0.030673841  v: 0.049247246\n",
      "Step: 221 Política Determinista - Accion 2\n",
      "Step: 222 Número Aleatorio: 0.36488848239927707 Epsilon: 0.15639999999999502\n",
      "Step: 222 x: 0.017083984  v: 0.047757827\n",
      "Step: 222 Política Determinista - Accion 2\n",
      "Step: 223 Número Aleatorio: 0.51526249882615 Epsilon: 0.15259999999999502\n",
      "Step: 223 x: 0.06334509  v: 0.04626111\n",
      "Step: 223 Política Determinista - Accion 2\n",
      "Step: 224 Número Aleatorio: 0.31578832593443673 Epsilon: 0.14879999999999502\n",
      "Step: 224 x: 0.108151205  v: 0.044806115\n",
      "Step: 224 Política Determinista - Accion 2\n",
      "Step: 225 Número Aleatorio: 0.4046585520323498 Epsilon: 0.14499999999999502\n",
      "Step: 225 x: 0.15158775  v: 0.043436553\n",
      "Step: 225 Política Determinista - Accion 2\n",
      "Step: 226 Número Aleatorio: 0.5362379811714779 Epsilon: 0.14119999999999502\n",
      "Step: 226 x: 0.1937784  v: 0.042190637\n",
      "Step: 226 Política Determinista - Accion 2\n",
      "Step: 227 Número Aleatorio: 0.915766636848856 Epsilon: 0.13739999999999503\n",
      "Step: 227 x: 0.23487972  v: 0.041101314\n",
      "Step: 227 Política Determinista - Accion 2\n",
      "Step: 228 Número Aleatorio: 0.28244246995473066 Epsilon: 0.13359999999999503\n",
      "Step: 228 x: 0.27507642  v: 0.040196702\n",
      "Step: 228 Política Determinista - Accion 2\n",
      "Step: 229 Número Aleatorio: 0.0911163921665058 Epsilon: 0.12979999999999503\n",
      "Step: 229 Política Aleatoria - Accion 0\n",
      "Step: 230 Número Aleatorio: 0.5669050685196882 Epsilon: 0.12599999999999503\n",
      "Step: 230 x: 0.35161093  v: 0.037033804\n",
      "Step: 230 Política Determinista - Accion 2\n",
      "Step: 231 Número Aleatorio: 0.1299983989449104 Epsilon: 0.12219999999999503\n",
      "Step: 231 x: 0.3884113  v: 0.03680037\n",
      "Step: 231 Política Determinista - Accion 2\n",
      "Step: 232 Número Aleatorio: 0.4085700757503543 Epsilon: 0.11839999999999504\n",
      "Step: 232 x: 0.42522535  v: 0.03681403\n",
      "Step: 232 Política Determinista - Accion 2\n",
      "Step: 233 Número Aleatorio: 0.4651081648403147 Epsilon: 0.11459999999999504\n",
      "Step: 233 x: 0.46231222  v: 0.037086893\n",
      "Step: 233 Política Determinista - Accion 2\n",
      "Step: 234 Número Aleatorio: 0.3292287655207621 Epsilon: 0.11079999999999504\n",
      "Step: 234 x: 0.49994206  v: 0.037629828\n",
      "Step: 234 Política Determinista - Accion 2\n",
      "Enhorabuena! Lo has logrado en 234 pasos\n"
     ]
    }
   ],
   "source": [
    "env_wrapper_probabilistico(policy_probabilista, env,steps,1.0) # O invoca tu wrapper modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:50:22.250265Z",
     "start_time": "2021-11-12T10:50:19.844822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Número Aleatorio: 0.5014600941769188 Epsilon: 0.25\n",
      "Step: 0 x: -0.54130685  v: 0.0\n",
      "Step: 0 Política Determinista - Accion 2\n",
      "Step: 1 Número Aleatorio: 0.5929279566878536 Epsilon: 0.2462\n",
      "Step: 1 x: -0.5401741  v: 0.0011327482\n",
      "Step: 1 Política Determinista - Accion 2\n",
      "Step: 2 Número Aleatorio: 0.5186380547758342 Epsilon: 0.2424\n",
      "Step: 2 x: -0.5379171  v: 0.0022570118\n",
      "Step: 2 Política Determinista - Accion 2\n",
      "Step: 3 Número Aleatorio: 0.8139967089504148 Epsilon: 0.2386\n",
      "Step: 3 x: -0.53455275  v: 0.0033643662\n",
      "Step: 3 Política Determinista - Accion 2\n",
      "Step: 4 Número Aleatorio: 0.22735082541001927 Epsilon: 0.2348\n",
      "Step: 4 Política Aleatoria - Accion 1\n",
      "Step: 5 Número Aleatorio: 0.20629788091188095 Epsilon: 0.231\n",
      "Step: 5 Política Aleatoria - Accion 0\n",
      "Step: 6 Número Aleatorio: 0.24421603864892893 Epsilon: 0.2272\n",
      "Step: 6 x: -0.5221005  v: 0.0035104\n",
      "Step: 6 Política Determinista - Accion 2\n",
      "Step: 7 Número Aleatorio: 0.797713258322568 Epsilon: 0.22340000000000002\n",
      "Step: 7 x: -0.5176014  v: 0.004499163\n",
      "Step: 7 Política Determinista - Accion 2\n",
      "Step: 8 Número Aleatorio: 0.127543679490706 Epsilon: 0.21960000000000002\n",
      "Step: 8 Política Aleatoria - Accion 0\n",
      "Step: 9 Número Aleatorio: 0.16855539697235244 Epsilon: 0.21580000000000002\n",
      "Step: 9 Política Aleatoria - Accion 2\n",
      "Step: 10 Número Aleatorio: 0.05127134224650709 Epsilon: 0.21200000000000002\n",
      "Step: 10 Política Aleatoria - Accion 1\n",
      "Step: 11 Número Aleatorio: 0.042757208107216615 Epsilon: 0.20820000000000002\n",
      "Step: 11 Política Aleatoria - Accion 2\n",
      "Step: 12 Número Aleatorio: 0.18030184171847352 Epsilon: 0.20440000000000003\n",
      "Step: 12 Política Aleatoria - Accion 0\n",
      "Step: 13 Número Aleatorio: 0.3839203108870185 Epsilon: 0.20060000000000003\n",
      "Step: 13 x: -0.48688585  v: 0.004655725\n",
      "Step: 13 Política Determinista - Accion 2\n",
      "Step: 14 Número Aleatorio: 0.3736119592374483 Epsilon: 0.19680000000000003\n",
      "Step: 14 x: -0.48150492  v: 0.005380934\n",
      "Step: 14 Política Determinista - Accion 2\n",
      "Step: 15 Número Aleatorio: 0.9330268936587287 Epsilon: 0.19300000000000003\n",
      "Step: 15 x: -0.47543883  v: 0.0060660685\n",
      "Step: 15 Política Determinista - Accion 2\n",
      "Step: 16 Número Aleatorio: 0.34503962399790333 Epsilon: 0.18920000000000003\n",
      "Step: 16 x: -0.4687327  v: 0.0067061246\n",
      "Step: 16 Política Determinista - Accion 2\n",
      "Step: 17 Número Aleatorio: 0.775634474112811 Epsilon: 0.18540000000000004\n",
      "Step: 17 x: -0.46143624  v: 0.0072964844\n",
      "Step: 17 Política Determinista - Accion 2\n",
      "Step: 18 Número Aleatorio: 0.4780018442463858 Epsilon: 0.18160000000000004\n",
      "Step: 18 x: -0.45360327  v: 0.007832963\n",
      "Step: 18 Política Determinista - Accion 2\n",
      "Step: 19 Número Aleatorio: 0.6404824580369225 Epsilon: 0.17780000000000004\n",
      "Step: 19 x: -0.44529143  v: 0.008311846\n",
      "Step: 19 Política Determinista - Accion 2\n",
      "Step: 20 Número Aleatorio: 0.6151132189249416 Epsilon: 0.17400000000000004\n",
      "Step: 20 x: -0.4365615  v: 0.008729928\n",
      "Step: 20 Política Determinista - Accion 2\n",
      "Step: 21 Número Aleatorio: 0.5829121562580736 Epsilon: 0.17020000000000005\n",
      "Step: 21 x: -0.42747694  v: 0.009084541\n",
      "Step: 21 Política Determinista - Accion 2\n",
      "Step: 22 Número Aleatorio: 0.5130930479012453 Epsilon: 0.16640000000000005\n",
      "Step: 22 x: -0.41810337  v: 0.009373577\n",
      "Step: 22 Política Determinista - Accion 2\n",
      "Step: 23 Número Aleatorio: 0.01090351675136747 Epsilon: 0.16260000000000005\n",
      "Step: 23 Política Aleatoria - Accion 2\n",
      "Step: 24 Número Aleatorio: 0.019086627313960713 Epsilon: 0.15880000000000005\n",
      "Step: 24 Política Aleatoria - Accion 0\n",
      "Step: 25 Número Aleatorio: 0.15308266137916993 Epsilon: 0.15500000000000005\n",
      "Step: 25 Política Aleatoria - Accion 1\n",
      "Step: 26 Número Aleatorio: 0.5712609524424773 Epsilon: 0.15120000000000006\n",
      "Step: 26 x: -0.38405788  v: 0.006865808\n",
      "Step: 26 Política Determinista - Accion 2\n",
      "Step: 27 Número Aleatorio: 0.5606839509021238 Epsilon: 0.14740000000000006\n",
      "Step: 27 x: -0.37720832  v: 0.0068495516\n",
      "Step: 27 Política Determinista - Accion 2\n",
      "Step: 28 Número Aleatorio: 0.4625307525024748 Epsilon: 0.14360000000000006\n",
      "Step: 28 x: -0.37042177  v: 0.006786578\n",
      "Step: 28 Política Determinista - Accion 2\n",
      "Step: 29 Número Aleatorio: 0.2561171141773546 Epsilon: 0.13980000000000006\n",
      "Step: 29 x: -0.363744  v: 0.006677758\n",
      "Step: 29 Política Determinista - Accion 2\n",
      "Step: 30 Número Aleatorio: 0.43780419717225316 Epsilon: 0.13600000000000007\n",
      "Step: 30 x: -0.35721973  v: 0.0065242765\n",
      "Step: 30 Política Determinista - Accion 2\n",
      "Step: 31 Número Aleatorio: 0.13668726738938242 Epsilon: 0.13220000000000007\n",
      "Step: 31 x: -0.35089213  v: 0.006327606\n",
      "Step: 31 Política Determinista - Accion 2\n",
      "Step: 32 Número Aleatorio: 0.16447915146257686 Epsilon: 0.12840000000000007\n",
      "Step: 32 x: -0.34480262  v: 0.0060894866\n",
      "Step: 32 Política Determinista - Accion 2\n",
      "Step: 33 Número Aleatorio: 0.9778878769346518 Epsilon: 0.12460000000000007\n",
      "Step: 33 x: -0.33899072  v: 0.005811899\n",
      "Step: 33 Política Determinista - Accion 2\n",
      "Step: 34 Número Aleatorio: 0.8366974886321509 Epsilon: 0.12080000000000007\n",
      "Step: 34 x: -0.33349368  v: 0.00549704\n",
      "Step: 34 Política Determinista - Accion 2\n",
      "Step: 35 Número Aleatorio: 0.2399692691306261 Epsilon: 0.11700000000000008\n",
      "Step: 35 x: -0.3283464  v: 0.0051472965\n",
      "Step: 35 Política Determinista - Accion 2\n",
      "Step: 36 Número Aleatorio: 0.9733970940608644 Epsilon: 0.11320000000000008\n",
      "Step: 36 x: -0.3235812  v: 0.0047652205\n",
      "Step: 36 Política Determinista - Accion 2\n",
      "Step: 37 Número Aleatorio: 0.4797801463766972 Epsilon: 0.10940000000000008\n",
      "Step: 37 x: -0.31922767  v: 0.0043535056\n",
      "Step: 37 Política Determinista - Accion 2\n",
      "Step: 38 Número Aleatorio: 0.7507965776568805 Epsilon: 0.10560000000000008\n",
      "Step: 38 x: -0.3153127  v: 0.003914964\n",
      "Step: 38 Política Determinista - Accion 2\n",
      "Step: 39 Número Aleatorio: 0.5851678881079099 Epsilon: 0.10180000000000008\n",
      "Step: 39 x: -0.3118602  v: 0.0034525085\n",
      "Step: 39 Política Determinista - Accion 2\n",
      "Step: 40 Número Aleatorio: 0.38357698432236853 Epsilon: 0.09800000000000009\n",
      "Step: 40 x: -0.30889106  v: 0.0029691304\n",
      "Step: 40 Política Determinista - Accion 2\n",
      "Step: 41 Número Aleatorio: 0.6890825147802704 Epsilon: 0.09420000000000009\n",
      "Step: 41 x: -0.3064232  v: 0.0024678868\n",
      "Step: 41 Política Determinista - Accion 2\n",
      "Step: 42 Número Aleatorio: 0.5524138330610144 Epsilon: 0.09040000000000009\n",
      "Step: 42 x: -0.30447128  v: 0.0019518839\n",
      "Step: 42 Política Determinista - Accion 2\n",
      "Step: 43 Número Aleatorio: 0.9934029754816918 Epsilon: 0.0866000000000001\n",
      "Step: 43 x: -0.30304703  v: 0.0014242666\n",
      "Step: 43 Política Determinista - Accion 2\n",
      "Step: 44 Número Aleatorio: 0.695747439519294 Epsilon: 0.0828000000000001\n",
      "Step: 44 x: -0.30215883  v: 0.0008882075\n",
      "Step: 44 Política Determinista - Accion 2\n",
      "Step: 45 Número Aleatorio: 0.3796094784447003 Epsilon: 0.0790000000000001\n",
      "Step: 45 x: -0.30181193  v: 0.00034689807\n",
      "Step: 45 Política Determinista - Accion 2\n",
      "Step: 46 Número Aleatorio: 0.1298107690097503 Epsilon: 0.0752000000000001\n",
      "Step: 46 x: -0.3020084  v: -0.00019645898\n",
      "Step: 46 Política Determinista - Accion 0\n",
      "Step: 47 Número Aleatorio: 0.2826555329360909 Epsilon: 0.0714000000000001\n",
      "Step: 47 x: -0.30474705  v: -0.0027386567\n",
      "Step: 47 Política Determinista - Accion 0\n",
      "Step: 48 Número Aleatorio: 0.7072200481520949 Epsilon: 0.0676000000000001\n",
      "Step: 48 x: -0.31001168  v: -0.005264636\n",
      "Step: 48 Política Determinista - Accion 0\n",
      "Step: 49 Número Aleatorio: 0.8972145903820022 Epsilon: 0.0638000000000001\n",
      "Step: 49 x: -0.31777084  v: -0.007759151\n",
      "Step: 49 Política Determinista - Accion 0\n",
      "Step: 50 Número Aleatorio: 0.6456578239695361 Epsilon: 0.06000000000000011\n",
      "Step: 50 x: -0.32797745  v: -0.010206615\n",
      "Step: 50 Política Determinista - Accion 0\n",
      "Step: 51 Número Aleatorio: 0.840559561917432 Epsilon: 0.05620000000000011\n",
      "Step: 51 x: -0.34056842  v: -0.012590996\n",
      "Step: 51 Política Determinista - Accion 0\n",
      "Step: 52 Número Aleatorio: 0.5387261419650984 Epsilon: 0.05240000000000011\n",
      "Step: 52 x: -0.35546422  v: -0.014895776\n",
      "Step: 52 Política Determinista - Accion 0\n",
      "Step: 53 Número Aleatorio: 0.6769065222793947 Epsilon: 0.048600000000000115\n",
      "Step: 53 x: -0.3725682  v: -0.01710399\n",
      "Step: 53 Política Determinista - Accion 0\n",
      "Step: 54 Número Aleatorio: 0.5963621421341954 Epsilon: 0.048600000000000115\n",
      "Step: 54 x: -0.39176655  v: -0.019198358\n",
      "Step: 54 Política Determinista - Accion 0\n",
      "Step: 55 Número Aleatorio: 0.4424126883062869 Epsilon: 0.048600000000000115\n",
      "Step: 55 x: -0.41292807  v: -0.021161525\n",
      "Step: 55 Política Determinista - Accion 0\n",
      "Step: 56 Número Aleatorio: 0.5317445595378387 Epsilon: 0.048600000000000115\n",
      "Step: 56 x: -0.43590447  v: -0.02297639\n",
      "Step: 56 Política Determinista - Accion 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 57 Número Aleatorio: 0.05629457009622574 Epsilon: 0.048600000000000115\n",
      "Step: 57 x: -0.460531  v: -0.024626536\n",
      "Step: 57 Política Determinista - Accion 0\n",
      "Step: 58 Número Aleatorio: 0.5501164068524459 Epsilon: 0.048600000000000115\n",
      "Step: 58 x: -0.48662773  v: -0.026096728\n",
      "Step: 58 Política Determinista - Accion 0\n",
      "Step: 59 Número Aleatorio: 0.1954913216708134 Epsilon: 0.048600000000000115\n",
      "Step: 59 x: -0.5140012  v: -0.027373442\n",
      "Step: 59 Política Determinista - Accion 0\n",
      "Step: 60 Número Aleatorio: 0.4868927784351017 Epsilon: 0.048600000000000115\n",
      "Step: 60 x: -0.5424466  v: -0.028445413\n",
      "Step: 60 Política Determinista - Accion 0\n",
      "Step: 61 Número Aleatorio: 0.7410341005676068 Epsilon: 0.048600000000000115\n",
      "Step: 61 x: -0.5717507  v: -0.02930413\n",
      "Step: 61 Política Determinista - Accion 0\n",
      "Step: 62 Número Aleatorio: 0.2537310235366892 Epsilon: 0.048600000000000115\n",
      "Step: 62 x: -0.60169494  v: -0.029944245\n",
      "Step: 62 Política Determinista - Accion 0\n",
      "Step: 63 Número Aleatorio: 0.2597314980894242 Epsilon: 0.048600000000000115\n",
      "Step: 63 x: -0.63205886  v: -0.030363867\n",
      "Step: 63 Política Determinista - Accion 0\n",
      "Step: 64 Número Aleatorio: 0.4012798678819379 Epsilon: 0.048600000000000115\n",
      "Step: 64 x: -0.6626235  v: -0.030564696\n",
      "Step: 64 Política Determinista - Accion 0\n",
      "Step: 65 Número Aleatorio: 0.38535076815939506 Epsilon: 0.048600000000000115\n",
      "Step: 65 x: -0.6931755  v: -0.030551977\n",
      "Step: 65 Política Determinista - Accion 0\n",
      "Step: 66 Número Aleatorio: 0.7577883905942752 Epsilon: 0.048600000000000115\n",
      "Step: 66 x: -0.7235098  v: -0.030334305\n",
      "Step: 66 Política Determinista - Accion 0\n",
      "Step: 67 Número Aleatorio: 0.49854015393599627 Epsilon: 0.048600000000000115\n",
      "Step: 67 x: -0.75343305  v: -0.029923249\n",
      "Step: 67 Política Determinista - Accion 0\n",
      "Step: 68 Número Aleatorio: 0.6828056386822763 Epsilon: 0.048600000000000115\n",
      "Step: 68 x: -0.7827659  v: -0.029332865\n",
      "Step: 68 Política Determinista - Accion 0\n",
      "Step: 69 Número Aleatorio: 0.06672283134660828 Epsilon: 0.048600000000000115\n",
      "Step: 69 x: -0.81134504  v: -0.028579114\n",
      "Step: 69 Política Determinista - Accion 0\n",
      "Step: 70 Número Aleatorio: 0.6503597952135354 Epsilon: 0.048600000000000115\n",
      "Step: 70 x: -0.8390243  v: -0.027679235\n",
      "Step: 70 Política Determinista - Accion 0\n",
      "Step: 71 Número Aleatorio: 0.2984221052855127 Epsilon: 0.048600000000000115\n",
      "Step: 71 x: -0.8656754  v: -0.026651124\n",
      "Step: 71 Política Determinista - Accion 0\n",
      "Step: 72 Número Aleatorio: 0.7161409220326873 Epsilon: 0.048600000000000115\n",
      "Step: 72 x: -0.89118814  v: -0.025512744\n",
      "Step: 72 Política Determinista - Accion 0\n",
      "Step: 73 Número Aleatorio: 0.6875939531454301 Epsilon: 0.048600000000000115\n",
      "Step: 73 x: -0.91546977  v: -0.024281595\n",
      "Step: 73 Política Determinista - Accion 0\n",
      "Step: 74 Número Aleatorio: 0.16834067195504576 Epsilon: 0.048600000000000115\n",
      "Step: 74 x: -0.938444  v: -0.02297428\n",
      "Step: 74 Política Determinista - Accion 0\n",
      "Step: 75 Número Aleatorio: 0.4741052897134894 Epsilon: 0.048600000000000115\n",
      "Step: 75 x: -0.96005017  v: -0.021606162\n",
      "Step: 75 Política Determinista - Accion 0\n",
      "Step: 76 Número Aleatorio: 0.13545138341963658 Epsilon: 0.048600000000000115\n",
      "Step: 76 x: -0.9802413  v: -0.020191116\n",
      "Step: 76 Política Determinista - Accion 0\n",
      "Step: 77 Número Aleatorio: 0.23636102633768397 Epsilon: 0.048600000000000115\n",
      "Step: 77 x: -0.99898267  v: -0.018741382\n",
      "Step: 77 Política Determinista - Accion 0\n",
      "Step: 78 Número Aleatorio: 0.6475882492584303 Epsilon: 0.048600000000000115\n",
      "Step: 78 x: -1.0162501  v: -0.01726749\n",
      "Step: 78 Política Determinista - Accion 0\n",
      "Step: 79 Número Aleatorio: 0.9319712723019072 Epsilon: 0.048600000000000115\n",
      "Step: 79 x: -1.0320284  v: -0.015778257\n",
      "Step: 79 Política Determinista - Accion 0\n",
      "Step: 80 Número Aleatorio: 0.8678700677254999 Epsilon: 0.048600000000000115\n",
      "Step: 80 x: -1.0463092  v: -0.0142808445\n",
      "Step: 80 Política Determinista - Accion 0\n",
      "Step: 81 Número Aleatorio: 0.7370617063859827 Epsilon: 0.048600000000000115\n",
      "Step: 81 x: -1.0590901  v: -0.012780853\n",
      "Step: 81 Política Determinista - Accion 0\n",
      "Step: 82 Número Aleatorio: 0.305120092700619 Epsilon: 0.048600000000000115\n",
      "Step: 82 x: -1.0703726  v: -0.011282444\n",
      "Step: 82 Política Determinista - Accion 0\n",
      "Step: 83 Número Aleatorio: 0.10812956146223485 Epsilon: 0.048600000000000115\n",
      "Step: 83 x: -1.0801611  v: -0.009788483\n",
      "Step: 83 Política Determinista - Accion 0\n",
      "Step: 84 Número Aleatorio: 0.5739466893624052 Epsilon: 0.048600000000000115\n",
      "Step: 84 x: -1.0884618  v: -0.008300698\n",
      "Step: 84 Política Determinista - Accion 0\n",
      "Step: 85 Número Aleatorio: 0.5442431364329839 Epsilon: 0.048600000000000115\n",
      "Step: 85 x: -1.0952816  v: -0.0068198293\n",
      "Step: 85 Política Determinista - Accion 0\n",
      "Step: 86 Número Aleatorio: 0.7434237274368155 Epsilon: 0.048600000000000115\n",
      "Step: 86 x: -1.1006274  v: -0.005345795\n",
      "Step: 86 Política Determinista - Accion 0\n",
      "Step: 87 Número Aleatorio: 0.39254152525651576 Epsilon: 0.048600000000000115\n",
      "Step: 87 x: -1.1045052  v: -0.003877842\n",
      "Step: 87 Política Determinista - Accion 0\n",
      "Step: 88 Número Aleatorio: 0.8461284169806478 Epsilon: 0.048600000000000115\n",
      "Step: 88 x: -1.1069199  v: -0.0024146982\n",
      "Step: 88 Política Determinista - Accion 0\n",
      "Step: 89 Número Aleatorio: 0.2569793285989813 Epsilon: 0.048600000000000115\n",
      "Step: 89 x: -1.1078746  v: -0.000954717\n",
      "Step: 89 Política Determinista - Accion 0\n",
      "Step: 90 Número Aleatorio: 0.7669534883167002 Epsilon: 0.048600000000000115\n",
      "Step: 90 x: -1.1073706  v: 0.00050397805\n",
      "Step: 90 Política Determinista - Accion 2\n",
      "Step: 91 Número Aleatorio: 0.10563877084659201 Epsilon: 0.048600000000000115\n",
      "Step: 91 x: -1.1034073  v: 0.0039633545\n",
      "Step: 91 Política Determinista - Accion 2\n",
      "Step: 92 Número Aleatorio: 0.25910624167725604 Epsilon: 0.048600000000000115\n",
      "Step: 92 x: -1.0959795  v: 0.007427894\n",
      "Step: 92 Política Determinista - Accion 2\n",
      "Step: 93 Número Aleatorio: 0.5218878875124566 Epsilon: 0.048600000000000115\n",
      "Step: 93 x: -1.0850782  v: 0.010901171\n",
      "Step: 93 Política Determinista - Accion 2\n",
      "Step: 94 Número Aleatorio: 0.037064039626858225 Epsilon: 0.048600000000000115\n",
      "Step: 94 Política Aleatoria - Accion 0\n",
      "Step: 95 Número Aleatorio: 0.6092704355463471 Epsilon: 0.048600000000000115\n",
      "Step: 95 x: -1.0548143  v: 0.015878838\n",
      "Step: 95 Política Determinista - Accion 2\n",
      "Step: 96 Número Aleatorio: 0.8725176375242348 Epsilon: 0.048600000000000115\n",
      "Step: 96 x: -1.0354362  v: 0.019378183\n",
      "Step: 96 Política Determinista - Accion 2\n",
      "Step: 97 Número Aleatorio: 0.04551705234524284 Epsilon: 0.048600000000000115\n",
      "Step: 97 Política Aleatoria - Accion 2\n",
      "Step: 98 Número Aleatorio: 0.43101240586016587 Epsilon: 0.048600000000000115\n",
      "Step: 98 x: -0.9861964  v: 0.026363142\n",
      "Step: 98 Política Determinista - Accion 2\n",
      "Step: 99 Número Aleatorio: 0.40599038864355597 Epsilon: 0.048600000000000115\n",
      "Step: 99 x: -0.956375  v: 0.029821396\n",
      "Step: 99 Política Determinista - Accion 2\n",
      "Step: 100 Número Aleatorio: 0.32199600259335526 Epsilon: 0.048600000000000115\n",
      "Step: 100 x: -0.92314583  v: 0.033229172\n",
      "Step: 100 Política Determinista - Accion 2\n",
      "Step: 101 Número Aleatorio: 0.48018541699173023 Epsilon: 0.048600000000000115\n",
      "Step: 101 x: -0.8865878  v: 0.036558036\n",
      "Step: 101 Política Determinista - Accion 2\n",
      "Step: 102 Número Aleatorio: 0.6284316158498197 Epsilon: 0.048600000000000115\n",
      "Step: 102 x: -0.8468144  v: 0.03977341\n",
      "Step: 102 Política Determinista - Accion 2\n",
      "Step: 103 Número Aleatorio: 0.24738272330185174 Epsilon: 0.048600000000000115\n",
      "Step: 103 x: -0.8039793  v: 0.042835124\n",
      "Step: 103 Política Determinista - Accion 2\n",
      "Step: 104 Número Aleatorio: 0.553380182075352 Epsilon: 0.048600000000000115\n",
      "Step: 104 x: -0.75828063  v: 0.045698635\n",
      "Step: 104 Política Determinista - Accion 2\n",
      "Step: 105 Número Aleatorio: 0.4230066123163023 Epsilon: 0.048600000000000115\n",
      "Step: 105 x: -0.70996374  v: 0.0483169\n",
      "Step: 105 Política Determinista - Accion 2\n",
      "Step: 106 Número Aleatorio: 0.49918444742229584 Epsilon: 0.048600000000000115\n",
      "Step: 106 x: -0.6593208  v: 0.05064295\n",
      "Step: 106 Política Determinista - Accion 2\n",
      "Step: 107 Número Aleatorio: 0.908420018833008 Epsilon: 0.048600000000000115\n",
      "Step: 107 x: -0.60668784  v: 0.05263297\n",
      "Step: 107 Política Determinista - Accion 2\n",
      "Step: 108 Número Aleatorio: 0.4847118484823535 Epsilon: 0.048600000000000115\n",
      "Step: 108 x: -0.55243814  v: 0.054249704\n",
      "Step: 108 Política Determinista - Accion 2\n",
      "Step: 109 Número Aleatorio: 0.69259283451584 Epsilon: 0.048600000000000115\n",
      "Step: 109 x: -0.49697238  v: 0.055465728\n",
      "Step: 109 Política Determinista - Accion 2\n",
      "Step: 110 Número Aleatorio: 0.9087710348200841 Epsilon: 0.048600000000000115\n",
      "Step: 110 x: -0.44070613  v: 0.056266245\n",
      "Step: 110 Política Determinista - Accion 2\n",
      "Step: 111 Número Aleatorio: 0.7775040025296748 Epsilon: 0.048600000000000115\n",
      "Step: 111 x: -0.3840552  v: 0.056650937\n",
      "Step: 111 Política Determinista - Accion 2\n",
      "Step: 112 Número Aleatorio: 0.3952563989436866 Epsilon: 0.048600000000000115\n",
      "Step: 112 x: -0.32742053  v: 0.05663466\n",
      "Step: 112 Política Determinista - Accion 2\n",
      "Step: 113 Número Aleatorio: 0.11572430189664906 Epsilon: 0.048600000000000115\n",
      "Step: 113 x: -0.27117375  v: 0.056246806\n",
      "Step: 113 Política Determinista - Accion 2\n",
      "Step: 114 Número Aleatorio: 0.3550485376909366 Epsilon: 0.048600000000000115\n",
      "Step: 114 x: -0.21564429  v: 0.055529445\n",
      "Step: 114 Política Determinista - Accion 2\n",
      "Step: 115 Número Aleatorio: 0.6088040965262185 Epsilon: 0.048600000000000115\n",
      "Step: 115 x: -0.16110969  v: 0.054534607\n",
      "Step: 115 Política Determinista - Accion 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 116 Número Aleatorio: 0.6312329217085451 Epsilon: 0.048600000000000115\n",
      "Step: 116 x: -0.10778871  v: 0.053320974\n",
      "Step: 116 Política Determinista - Accion 2\n",
      "Step: 117 Número Aleatorio: 0.4484085045406483 Epsilon: 0.048600000000000115\n",
      "Step: 117 x: -0.055838168  v: 0.051950544\n",
      "Step: 117 Política Determinista - Accion 2\n",
      "Step: 118 Número Aleatorio: 0.18219703197122117 Epsilon: 0.048600000000000115\n",
      "Step: 118 x: -0.0053526266  v: 0.05048554\n",
      "Step: 118 Política Determinista - Accion 2\n",
      "Step: 119 Número Aleatorio: 0.1555148403309401 Epsilon: 0.048600000000000115\n",
      "Step: 119 x: 0.043633234  v: 0.04898586\n",
      "Step: 119 Política Determinista - Accion 2\n",
      "Step: 120 Número Aleatorio: 0.22277468788819732 Epsilon: 0.048600000000000115\n",
      "Step: 120 x: 0.09114049  v: 0.04750725\n",
      "Step: 120 Política Determinista - Accion 2\n",
      "Step: 121 Número Aleatorio: 0.5472677108278953 Epsilon: 0.048600000000000115\n",
      "Step: 121 x: 0.1372406  v: 0.046100117\n",
      "Step: 121 Política Determinista - Accion 2\n",
      "Step: 122 Número Aleatorio: 0.19811890896320195 Epsilon: 0.048600000000000115\n",
      "Step: 122 x: 0.18204963  v: 0.044809036\n",
      "Step: 122 Política Determinista - Accion 2\n",
      "Step: 123 Número Aleatorio: 0.2342756978085433 Epsilon: 0.048600000000000115\n",
      "Step: 123 x: 0.22572234  v: 0.043672707\n",
      "Step: 123 Política Determinista - Accion 2\n",
      "Step: 124 Número Aleatorio: 0.16973502011908226 Epsilon: 0.048600000000000115\n",
      "Step: 124 x: 0.26844668  v: 0.04272433\n",
      "Step: 124 Política Determinista - Accion 2\n",
      "Step: 125 Número Aleatorio: 0.24963612850035288 Epsilon: 0.048600000000000115\n",
      "Step: 125 x: 0.31043884  v: 0.041992165\n",
      "Step: 125 Política Determinista - Accion 2\n",
      "Step: 126 Número Aleatorio: 0.02307514889310036 Epsilon: 0.048600000000000115\n",
      "Step: 126 Política Aleatoria - Accion 0\n",
      "Step: 127 Número Aleatorio: 0.18986188348130917 Epsilon: 0.048600000000000115\n",
      "Step: 127 x: 0.391208  v: 0.03926893\n",
      "Step: 127 Política Determinista - Accion 2\n",
      "Step: 128 Número Aleatorio: 0.0672947721462519 Epsilon: 0.048600000000000115\n",
      "Step: 128 x: 0.4305099  v: 0.0393019\n",
      "Step: 128 Política Determinista - Accion 2\n",
      "Step: 129 Número Aleatorio: 0.8791366359055901 Epsilon: 0.048600000000000115\n",
      "Step: 129 x: 0.47012267  v: 0.03961277\n",
      "Step: 129 Política Determinista - Accion 2\n",
      "Enhorabuena! Lo has logrado en 129 pasos\n"
     ]
    }
   ],
   "source": [
    "env_wrapper_probabilistico(policy_probabilista, env,steps,0.25) # O invoca tu wrapper modificado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando velocidad del coche\n",
    "\n",
    "Ahora queremos utilizar la velocidad actual del coche (segundo elemento de la observación retornada por el entorno) para lograr el objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:50:30.548898Z",
     "start_time": "2021-11-12T10:50:30.542065Z"
    }
   },
   "outputs": [],
   "source": [
    "def policy_speed(observation, step, *args):\n",
    "    speed = observation[1]\n",
    "    action = 0 if speed < 0 else 2# YOUR CODE HERE # solo velocidad no la posición parecido al que hemos hecho.\n",
    "    \n",
    "    return action\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:50:35.401361Z",
     "start_time": "2021-11-12T10:50:33.145022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhorabuena! Lo has logrado en 121 pasos\n"
     ]
    }
   ],
   "source": [
    "env_wrapper(policy_speed, env, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando *nuestra* velocidad del coche (Ejercicio extra)\n",
    "\n",
    "Es evidente que la información que tengamos sobre el estado es muy importante para establecer políticas efectivas. En este caso, el propio entorno de `gym` nos aporta la posición y la velocidad, pero hay otros datos que no los da directamente y podrían ser útiles, como la altura o la aceleración.\n",
    "\n",
    "El tener toda la información relevante para caracterizar un estado es vital, y está estrechamente relacionado con que se cumpla la propiedad Markoviana que estudiaremos en la siguiente [lección](../../s2/s2_worksheet.ipynb).\n",
    "\n",
    "Imagina que el entorno sólo diera la posición en cada estado, y no la velocidad. \n",
    "* ¿Sería posible, dada la información de sólo un estado, estimar la velocidad del mismo estado?\n",
    "* ¿Qué pasa si, además de tener la información del estado actual, conservamos la información del estado immediatamente anterior?\n",
    "\n",
    "Esbribe una política exitosa utilizando sólamente las posiciones del estado actual y el inmediatamente anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:50:46.542869Z",
     "start_time": "2021-11-12T10:50:46.536033Z"
    }
   },
   "outputs": [],
   "source": [
    "steps = 250\n",
    "def policy_speed_markovian(observation, step, previous_observation):\n",
    "    posicion = observation[0]\n",
    "    posicion_prev = previous_observation[0]\n",
    "    print(\"Pos: %s. Prev Pos: %s.\" % (posicion, posicion_prev))\n",
    "    action = 0 if (posicion-posicion_prev) < 0 else 2 # YOUR CODE HERE #\n",
    "    return action \n",
    "#Markov solo depende del estado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T10:50:51.034931Z",
     "start_time": "2021-11-12T10:50:48.780319Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: -0.46817857. Prev Pos: -0.46817857.\n",
      "Pos: -0.46759233. Prev Pos: -0.46817857.\n",
      "Pos: -0.46642414. Prev Pos: -0.46759233.\n",
      "Pos: -0.46468267. Prev Pos: -0.46642414.\n",
      "Pos: -0.46238077. Prev Pos: -0.46468267.\n",
      "Pos: -0.45953542. Prev Pos: -0.46238077.\n",
      "Pos: -0.45616758. Prev Pos: -0.45953542.\n",
      "Pos: -0.45230207. Prev Pos: -0.45616758.\n",
      "Pos: -0.4479672. Prev Pos: -0.45230207.\n",
      "Pos: -0.4431947. Prev Pos: -0.4479672.\n",
      "Pos: -0.43801942. Prev Pos: -0.4431947.\n",
      "Pos: -0.43247893. Prev Pos: -0.43801942.\n",
      "Pos: -0.4266134. Prev Pos: -0.43247893.\n",
      "Pos: -0.420465. Prev Pos: -0.4266134.\n",
      "Pos: -0.41407785. Prev Pos: -0.420465.\n",
      "Pos: -0.40749738. Prev Pos: -0.41407785.\n",
      "Pos: -0.4007702. Prev Pos: -0.40749738.\n",
      "Pos: -0.39394352. Prev Pos: -0.4007702.\n",
      "Pos: -0.3870649. Prev Pos: -0.39394352.\n",
      "Pos: -0.3801819. Prev Pos: -0.3870649.\n",
      "Pos: -0.37334168. Prev Pos: -0.3801819.\n",
      "Pos: -0.36659056. Prev Pos: -0.37334168.\n",
      "Pos: -0.35997397. Prev Pos: -0.36659056.\n",
      "Pos: -0.35353586. Prev Pos: -0.35997397.\n",
      "Pos: -0.34731862. Prev Pos: -0.35353586.\n",
      "Pos: -0.34136268. Prev Pos: -0.34731862.\n",
      "Pos: -0.33570647. Prev Pos: -0.34136268.\n",
      "Pos: -0.33038598. Prev Pos: -0.33570647.\n",
      "Pos: -0.3254348. Prev Pos: -0.33038598.\n",
      "Pos: -0.32088384. Prev Pos: -0.3254348.\n",
      "Pos: -0.31676126. Prev Pos: -0.32088384.\n",
      "Pos: -0.3130923. Prev Pos: -0.31676126.\n",
      "Pos: -0.30989927. Prev Pos: -0.3130923.\n",
      "Pos: -0.30720142. Prev Pos: -0.30989927.\n",
      "Pos: -0.30501494. Prev Pos: -0.30720142.\n",
      "Pos: -0.30335283. Prev Pos: -0.30501494.\n",
      "Pos: -0.302225. Prev Pos: -0.30335283.\n",
      "Pos: -0.30163807. Prev Pos: -0.302225.\n",
      "Pos: -0.3015955. Prev Pos: -0.30163807.\n",
      "Pos: -0.3020976. Prev Pos: -0.3015955.\n",
      "Pos: -0.30514136. Prev Pos: -0.3020976.\n",
      "Pos: -0.31070876. Prev Pos: -0.30514136.\n",
      "Pos: -0.31876647. Prev Pos: -0.31070876.\n",
      "Pos: -0.32926556. Prev Pos: -0.31876647.\n",
      "Pos: -0.34214097. Prev Pos: -0.32926556.\n",
      "Pos: -0.35731107. Prev Pos: -0.34214097.\n",
      "Pos: -0.37467727. Prev Pos: -0.35731107.\n",
      "Pos: -0.39412358. Prev Pos: -0.37467727.\n",
      "Pos: -0.4155167. Prev Pos: -0.39412358.\n",
      "Pos: -0.43870634. Prev Pos: -0.4155167.\n",
      "Pos: -0.4635258. Prev Pos: -0.43870634.\n",
      "Pos: -0.48979336. Prev Pos: -0.4635258.\n",
      "Pos: -0.517314. Prev Pos: -0.48979336.\n",
      "Pos: -0.54588187. Prev Pos: -0.517314.\n",
      "Pos: -0.57528263. Prev Pos: -0.54588187.\n",
      "Pos: -0.6052974. Prev Pos: -0.57528263.\n",
      "Pos: -0.6357055. Prev Pos: -0.6052974.\n",
      "Pos: -0.66628855. Prev Pos: -0.6357055.\n",
      "Pos: -0.69683385. Prev Pos: -0.66628855.\n",
      "Pos: -0.72713757. Prev Pos: -0.69683385.\n",
      "Pos: -0.75700784. Prev Pos: -0.72713757.\n",
      "Pos: -0.78626716. Prev Pos: -0.75700784.\n",
      "Pos: -0.8147541. Prev Pos: -0.78626716.\n",
      "Pos: -0.8423247. Prev Pos: -0.8147541.\n",
      "Pos: -0.86885273. Prev Pos: -0.8423247.\n",
      "Pos: -0.8942301. Prev Pos: -0.86885273.\n",
      "Pos: -0.91836625. Prev Pos: -0.8942301.\n",
      "Pos: -0.9411867. Prev Pos: -0.91836625.\n",
      "Pos: -0.9626326. Prev Pos: -0.9411867.\n",
      "Pos: -0.98265845. Prev Pos: -0.9626326.\n",
      "Pos: -1.0012311. Prev Pos: -0.98265845.\n",
      "Pos: -1.0183274. Prev Pos: -1.0012311.\n",
      "Pos: -1.033933. Prev Pos: -1.0183274.\n",
      "Pos: -1.0480407. Prev Pos: -1.033933.\n",
      "Pos: -1.0606484. Prev Pos: -1.0480407.\n",
      "Pos: -1.0717582. Prev Pos: -1.0606484.\n",
      "Pos: -1.0813746. Prev Pos: -1.0717582.\n",
      "Pos: -1.0895044. Prev Pos: -1.0813746.\n",
      "Pos: -1.0961541. Prev Pos: -1.0895044.\n",
      "Pos: -1.1013308. Prev Pos: -1.0961541.\n",
      "Pos: -1.1050403. Prev Pos: -1.1013308.\n",
      "Pos: -1.1072874. Prev Pos: -1.1050403.\n",
      "Pos: -1.108075. Prev Pos: -1.1072874.\n",
      "Pos: -1.1074041. Prev Pos: -1.108075.\n",
      "Pos: -1.103274. Prev Pos: -1.1074041.\n",
      "Pos: -1.0956792. Prev Pos: -1.103274.\n",
      "Pos: -1.0846107. Prev Pos: -1.0956792.\n",
      "Pos: -1.070058. Prev Pos: -1.0846107.\n",
      "Pos: -1.0520111. Prev Pos: -1.070058.\n",
      "Pos: -1.0304645. Prev Pos: -1.0520111.\n",
      "Pos: -1.0054212. Prev Pos: -1.0304645.\n",
      "Pos: -0.9768973. Prev Pos: -1.0054212.\n",
      "Pos: -0.9449289. Prev Pos: -0.9768973.\n",
      "Pos: -0.9095772. Prev Pos: -0.9449289.\n",
      "Pos: -0.87093556. Prev Pos: -0.9095772.\n",
      "Pos: -0.82913536. Prev Pos: -0.87093556.\n",
      "Pos: -0.7843513. Prev Pos: -0.82913536.\n",
      "Pos: -0.7368051. Prev Pos: -0.7843513.\n",
      "Pos: -0.68676656. Prev Pos: -0.7368051.\n",
      "Pos: -0.63455266. Prev Pos: -0.68676656.\n",
      "Pos: -0.5805218. Prev Pos: -0.63455266.\n",
      "Pos: -0.52506614. Prev Pos: -0.5805218.\n",
      "Pos: -0.4685995. Prev Pos: -0.52506614.\n",
      "Pos: -0.41154346. Prev Pos: -0.4685995.\n",
      "Pos: -0.35431206. Prev Pos: -0.41154346.\n",
      "Pos: -0.29729646. Prev Pos: -0.35431206.\n",
      "Pos: -0.24085073. Prev Pos: -0.29729646.\n",
      "Pos: -0.1852803. Prev Pos: -0.24085073.\n",
      "Pos: -0.13083349. Prev Pos: -0.1852803.\n",
      "Pos: -0.077696584. Prev Pos: -0.13083349.\n",
      "Pos: -0.025992068. Prev Pos: -0.077696584.\n",
      "Pos: 0.024220044. Prev Pos: -0.025992068.\n",
      "Pos: 0.072938755. Prev Pos: 0.024220044.\n",
      "Pos: 0.12021708. Prev Pos: 0.072938755.\n",
      "Pos: 0.16615623. Prev Pos: 0.12021708.\n",
      "Pos: 0.21089959. Prev Pos: 0.16615623.\n",
      "Pos: 0.25462687. Prev Pos: 0.21089959.\n",
      "Pos: 0.29754877. Prev Pos: 0.25462687.\n",
      "Pos: 0.33990225. Prev Pos: 0.29754877.\n",
      "Pos: 0.3819467. Prev Pos: 0.33990225.\n",
      "Pos: 0.42396048. Prev Pos: 0.3819467.\n",
      "Pos: 0.46623802. Prev Pos: 0.42396048.\n",
      "Enhorabuena! Lo has logrado en 121 pasos\n"
     ]
    }
   ],
   "source": [
    "env_wrapper(policy_speed_markovian, env, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.2",
    "jupytext_version": "1.4.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
